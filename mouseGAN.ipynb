{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  os.system(\"git clone https://github.com/matt-nann/AuthenticCursor.git\")\n",
    "  try:\n",
    "    shutil.copytree(\"AuthenticCursor/src\", \"src\")\n",
    "  except:\n",
    "    shutil.rmtree(\"src\")\n",
    "    shutil.copytree(\"AuthenticCursor/src\", \"src\")\n",
    "  try:\n",
    "    shutil.copy(\"AuthenticCursor/requirementsGAN.txt\", \"requirementsGAN.txt\")\n",
    "  except:\n",
    "    shutil.rmtree(\"requirementsGAN.txt\")\n",
    "    shutil.copy(\"AuthenticCursor/requirementsGAN.txt\", \"requirementsGAN.txt\")\n",
    "  # remove conflicting dependencies with google colab preinstalled libraries\n",
    "  with open(\"requirementsGAN.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    with open(\"requirementsGAN.txt\", \"w\") as f:\n",
    "      for line in lines:\n",
    "        if \"numpy\" not in line and 'pillow' not in line:\n",
    "          f.write(line)\n",
    "  os.system(\"pip install -r requirementsGAN.txt\")\n",
    "  shutil.rmtree(\"AuthenticCursor\")\n",
    "  # installing and logging into weights and biases\n",
    "  os.system(\"pip install wandb\")\n",
    "  os.system(\"wandb login\")\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "import torch\n",
    "import wandb # will be prompted for API key in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mouseGAN.dataProcessing import MouseGAN_Data\n",
    "from src.mouseGAN.dataset import getDataloader, visuallyVertifyDataloader\n",
    "\n",
    "USE_FAKE_DATA = True\n",
    "SAVE_FAKE_DATA = False\n",
    "RELOAD_FAKE_DATA = True\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "dataset = MouseGAN_Data(USE_FAKE_DATA=USE_FAKE_DATA, TRAIN_TEST_SPLIT=TRAIN_TEST_SPLIT, \n",
    "                        equal_length=False)\n",
    "\n",
    "SAMPLES = 30000\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if USE_FAKE_DATA:\n",
    "    if RELOAD_FAKE_DATA:\n",
    "        dataset.createFakeWindMouseDataset(save=SAVE_FAKE_DATA, samples=SAMPLES,\n",
    "                                        low_radius = 200, high_radius = 1000,\n",
    "                                        max_width = 300, min_width = 25,\n",
    "                                        max_height = 300, min_height = 25,)\n",
    "    else:\n",
    "        dataset.loadFakeWindMouseData()\n",
    "else:\n",
    "    df_moves, df_trajectory = dataset.collectRawMouseTrajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "s_time = time.time()\n",
    "train_trajs, train_targets, test_trajs, test_targets = dataset.processMouseData(SHOW_ALL=False)\n",
    "print(f\"Time to process data: {time.time() - s_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mouseGAN.model_config import Config, LR_SCHEDULERS, LOSS_FUNC, \\\n",
    "    C_MiniBatchDisc, C_Discriminator, C_Generator, C_EMA_Plateua_Sch, \\\n",
    "    C_Step_Sch, C_LossGap_Sch\n",
    "from src.mouseGAN.models import MouseGAN\n",
    "from src.mouseGAN.experimentTracker import initialize_wandb\n",
    "\n",
    "# IN_COLAB = True\n",
    "LOAD_PRETRAINED = False\n",
    "BATCH_SIZE = 256\n",
    "num_epochs = 1000\n",
    "num_feats = train_trajs[0].shape[1]\n",
    "latent_dim = 100\n",
    "num_target_feats = 4 # width, height, start_x, start_y\n",
    "MAX_SEQ_LEN = max([len(traj) for traj in train_trajs + test_trajs])\n",
    "\n",
    "D_config = C_Discriminator(lr=0.0001, bidirectional=True, hidden_units=128, \n",
    "                            num_lstm_layers=4, useEndDeviationLoss=True,\n",
    "                            gradient_maxNorm = 1.0,)\n",
    "G_config = C_Generator(lr=0.0001, hidden_units=128, num_lstm_layers=4, useOutsideTargetLoss=True, drop_prob=0.1,\n",
    "                layer_normalization = True,\n",
    "                residual_connections = True,\n",
    "                gradient_maxNorm = 1.0,)\n",
    "\n",
    "# D_sch_config = C_Step_Sch(2, 0.5)\n",
    "D_sch_config = C_LossGap_Sch(cooldown=int(BATCH_SIZE)/8, lr_shrinkMin=0.1, lr_growthMax=2.0, \n",
    "                            discLossDecay=0.8, lr_max = 0.0005, lr_min = 1*10**(-9))\n",
    "# G_sch_config = C_Step_Sch(2, 0.5)\n",
    "# G_sch_config = C_EMA_Plateua_Sch(patience=BATCH_SIZE, cooldown=int(BATCH_SIZE/8), factor=0.5, ema_alpha=0.4)\n",
    "\n",
    "config = Config(num_epochs, BATCH_SIZE, num_feats, latent_dim, num_target_feats, MAX_SEQ_LEN,\n",
    "                discriminator=D_config, generator=G_config, \n",
    "                D_lr_scheduler=D_sch_config, #G_lr_scheduler=G_sch_config,\n",
    "                locationMSELoss = False)\n",
    "\n",
    "## verifying the mean trajectory is centered around zero (even class distribution)\n",
    "# dataset.plotMeanPath()\n",
    "trainDataloader = getDataloader(train_trajs, train_targets, config.BATCH_SIZE)\n",
    "testDataloader = getDataloader(test_trajs, test_targets, config.BATCH_SIZE)\n",
    "\n",
    "visuallyVertifyDataloader(trainDataloader, dataset, showNumBatches=1)\n",
    "\n",
    "if IN_COLAB:\n",
    "    run = initialize_wandb(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gan = MouseGAN(dataset, trainDataloader, testDataloader, device, config, IN_COLAB=IN_COLAB, verbose=True, printBatch=True)\n",
    "if LOAD_PRETRAINED:\n",
    "    \n",
    "    gan.loadPretrained(startingEpoch='final')\n",
    "\n",
    "print(gan.discriminator)\n",
    "print(gan.generator)\n",
    "\n",
    "gan.train(modelSaveInterval=3, catchErrors=False)\n",
    "if IN_COLAB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.visualTrainingVerfication(samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(modelSaveInterval=3, catchErrors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.save_models('final')\n",
    "gan.loadPretrained(startingEpoch=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in ['final']:\n",
    "    gan.loadPretrained(startingEpoch=epoch)\n",
    "    gan.visualTrainingVerfication()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
