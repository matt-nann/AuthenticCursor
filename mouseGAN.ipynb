{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  os.system(\"git clone https://github.com/matt-nann/AuthenticCursor.git\")\n",
    "  try:\n",
    "    shutil.copytree(\"AuthenticCursor/src\", \"src\")\n",
    "  except:\n",
    "    shutil.rmtree(\"src\")\n",
    "    shutil.copytree(\"AuthenticCursor/src\", \"src\")\n",
    "  try:\n",
    "    shutil.copy(\"AuthenticCursor/requirementsGAN.txt\", \"requirementsGAN.txt\")\n",
    "  except:\n",
    "    shutil.rmtree(\"requirementsGAN.txt\")\n",
    "    shutil.copy(\"AuthenticCursor/requirementsGAN.txt\", \"requirementsGAN.txt\")\n",
    "  # remove conflicting dependencies with google colab preinstalled libraries\n",
    "  with open(\"requirementsGAN.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    with open(\"requirementsGAN.txt\", \"w\") as f:\n",
    "      for line in lines:\n",
    "        if \"numpy\" not in line and 'pillow' not in line:\n",
    "          f.write(line)\n",
    "  os.system(\"pip install -r requirementsGAN.txt\")\n",
    "  shutil.rmtree(\"AuthenticCursor\")\n",
    "  # installing and logging into weights and biases\n",
    "  os.system(\"pip install wandb\")\n",
    "  os.system(\"wandb login\")\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "import torch\n",
    "import wandb # will be prompted for API key in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mouseGAN.dataProcessing import MouseGAN_Data\n",
    "from src.mouseGAN.dataset import getDataloader, visuallyVertifyDataloader\n",
    "\n",
    "USE_FAKE_DATA = True\n",
    "SAVE_FAKE_DATA = False\n",
    "RELOAD_FAKE_DATA = True\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "dataset = MouseGAN_Data(USE_FAKE_DATA=USE_FAKE_DATA, TRAIN_TEST_SPLIT=TRAIN_TEST_SPLIT, \n",
    "                        equal_length=True, lowerLimit=25, upperLimit=30)\n",
    "\n",
    "SAMPLES = 20000\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if USE_FAKE_DATA:\n",
    "    if RELOAD_FAKE_DATA:\n",
    "        dataset.createFakeWindMouseDataset(save=SAVE_FAKE_DATA, samples=SAMPLES,\n",
    "                                        low_radius = 200, high_radius = 300,\n",
    "                                        max_width = 200, min_width = 50,\n",
    "                                        max_height = 100, min_height = 25,)\n",
    "    else:\n",
    "        dataset.loadFakeWindMouseData()\n",
    "else:\n",
    "    df_moves, df_trajectory = dataset.collectRawMouseTrajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trajs, train_targets, test_trajs, test_targets = dataset.processMouseData(SHOW_ALL=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "trainDataloader = getDataloader(train_trajs, train_targets, BATCH_SIZE)\n",
    "testDataloader = getDataloader(test_trajs, test_targets, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## verifying the mean trajectory is centered around zero (even class distribution)\n",
    "# dataset.plotMeanPath()\n",
    "\n",
    "visuallyVertifyDataloader(trainDataloader, dataset, showNumBatches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (miniBatch): MinibatchDiscrimination()\n",
      "  (lstm): LSTM(11, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (score_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (endLoc_layer): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Generator(\n",
      "  (fc_layer1): Linear(in_features=106, out_features=128, bias=True)\n",
      "  (lstm_cells): ModuleList(\n",
      "    (0-3): 4 x LSTMCell(128, 128)\n",
      "  )\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc_layer2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n",
      "d_loss 4.069591522216797 base_d_loss 1.0002200603485107\n",
      "d_loss 4.089595317840576 base_d_loss 0.9991632103919983\n",
      "d_loss 4.088871479034424 base_d_loss 0.998546838760376\n",
      "d_loss 4.11557674407959 base_d_loss 0.9979090690612793\n",
      "d_loss 4.078731536865234 base_d_loss 0.9947282075881958\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(gan\u001b[39m.\u001b[39mdiscriminator)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(gan\u001b[39m.\u001b[39mgenerator)\n\u001b[0;32m---> 38\u001b[0m gan\u001b[39m.\u001b[39;49mtrain(modelSaveInterval\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, catchErrors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m IN_COLAB:\n\u001b[1;32m     40\u001b[0m     wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/Documents/Code/AuthenticCursor/src/mouseGAN/models.py:313\u001b[0m, in \u001b[0;36mMouseGAN.train\u001b[0;34m(self, modelSaveInterval, sample_interval, num_plot_paths, output_dir, catchErrors)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_metrics \u001b[39m=\u001b[39m {}\n\u001b[1;32m    312\u001b[0m s_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 313\u001b[0m d_loss, g_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(epoch)\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m sample_interval \u001b[39mand\u001b[39;00m (epoch \u001b[39m%\u001b[39m sample_interval) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/AuthenticCursor/src/mouseGAN/models.py:505\u001b[0m, in \u001b[0;36mMouseGAN.train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    502\u001b[0m d_loss, base_d_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminatorLoss(d_real_out, d_real_predictedEnd, d_fake_out, d_fake_predictedEnd,\n\u001b[1;32m    503\u001b[0m                                 mouse_trajectories, fake_traj, normButtonLocs, d_states)\n\u001b[1;32m    504\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39md_loss\u001b[39m\u001b[39m\"\u001b[39m, d_loss\u001b[39m.\u001b[39mitem(), \u001b[39m\"\u001b[39m\u001b[39mbase_d_loss\u001b[39m\u001b[39m\"\u001b[39m, base_d_loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m--> 505\u001b[0m d_loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# retain_graph=True compute gradients of all variables wrt loss\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_D\u001b[39m.\u001b[39mstep() \u001b[39m# perform updates using calculated gradients\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_G\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/Code/AuthenticCursor/venvDev/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Code/AuthenticCursor/venvDev/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.mouseGAN.model_config import Config, LR_SCHEDULERS, LOSS_FUNC, \\\n",
    "    C_MiniBatchDisc, C_Discriminator, C_Generator, C_EMA_Plateua_Sch, \\\n",
    "    C_Step_Sch, C_LossGap_Sch\n",
    "from src.mouseGAN.models import MouseGAN\n",
    "from src.mouseGAN.experimentTracker import initialize_wandb\n",
    "\n",
    "LOAD_PRETRAINED = False\n",
    "\n",
    "num_epochs = 1000\n",
    "num_feats = train_trajs[0].shape[1]\n",
    "latent_dim = 100\n",
    "num_target_feats = 4 # width, height, start_x, start_y\n",
    "MAX_SEQ_LEN = train_trajs[0].shape[0]\n",
    "\n",
    "D_config = C_Discriminator(lr=0.0001, bidirectional=True, hidden_units=128, num_lstm_layers=4, useEndDeviationLoss=True)\n",
    "G_config = C_Generator(lr=0.0001, hidden_units=128, num_lstm_layers=4, useOutsideTargetLoss=True, drop_prob=0.25)\n",
    "\n",
    "# D_sch_config = C_Step_Sch(2, 0.5)\n",
    "D_sch_config = C_LossGap_Sch(cooldown=int(BATCH_SIZE)/8, lr_shrinkMin=0.1, lr_growthMax=2.0, \n",
    "                            discLossDecay=0.8, lr_max = 0.0005, lr_min = 1*10**(-9))\n",
    "# G_sch_config = C_Step_Sch(2, 0.5)\n",
    "# G_sch_config = C_EMA_Plateua_Sch(patience=BATCH_SIZE, cooldown=int(BATCH_SIZE/8), factor=0.5, ema_alpha=0.4)\n",
    "\n",
    "config = Config(num_epochs, BATCH_SIZE, num_feats, latent_dim, num_target_feats, MAX_SEQ_LEN,\n",
    "                discriminator=D_config, generator=G_config, \n",
    "                D_lr_scheduler=D_sch_config, #G_lr_scheduler=G_sch_config,\n",
    "                locationMSELoss = False)\n",
    "if IN_COLAB:\n",
    "    run = initialize_wandb(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gan = MouseGAN(dataset, trainDataloader, testDataloader, device, config, IN_COLAB=IN_COLAB, verbose=True, printBatch=True)\n",
    "if LOAD_PRETRAINED:\n",
    "    gan.loadPretrained(startingEpoch='final')\n",
    "\n",
    "print(gan.discriminator)\n",
    "print(gan.generator)\n",
    "\n",
    "gan.train(modelSaveInterval=3, catchErrors=False)\n",
    "if IN_COLAB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>D_lr</td><td>▁</td></tr><tr><td>G_lr</td><td>▁</td></tr><tr><td>d_fake_out</td><td>▁</td></tr><tr><td>d_loss</td><td>▁</td></tr><tr><td>d_loss_fake</td><td>▁</td></tr><tr><td>d_loss_fake_dev</td><td>▁</td></tr><tr><td>d_loss_real</td><td>▁</td></tr><tr><td>d_loss_real_dev</td><td>▁</td></tr><tr><td>d_real_out</td><td>▁</td></tr><tr><td>g_loss</td><td>▁</td></tr><tr><td>g_loss_missed</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>D_lr</td><td>0.0002</td></tr><tr><td>G_lr</td><td>0.0001</td></tr><tr><td>d_fake_out</td><td>0.04033</td></tr><tr><td>d_loss</td><td>4.09003</td></tr><tr><td>d_loss_fake</td><td>1.08229</td></tr><tr><td>d_loss_fake_dev</td><td>4.62336</td></tr><tr><td>d_loss_real</td><td>0.92048</td></tr><tr><td>d_loss_real_dev</td><td>1.55393</td></tr><tr><td>d_real_out</td><td>0.0406</td></tr><tr><td>g_loss</td><td>10.83242</td></tr><tr><td>g_loss_missed</td><td>9.88477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-cloud-25</strong> at: <a href='https://wandb.ai/mnann/mouseGAN/runs/51jj5n8g' target=\"_blank\">https://wandb.ai/mnann/mouseGAN/runs/51jj5n8g</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230614_131257-51jj5n8g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.visualTrainingVerfication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(modelSaveInterval=3, catchErrors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.save_models('final')\n",
    "gan.loadPretrained(startingEpoch=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in ['final']:\n",
    "    gan.loadPretrained(startingEpoch=epoch)\n",
    "    gan.visualTrainingVerfication()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
