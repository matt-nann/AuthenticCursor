{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (3621095602.py, line 607)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 607\u001b[0;36m\u001b[0m\n\u001b[0;31m    batch_metrics.update({name: value for name, value.item() in zip(logsPerBatchNames, values)})\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %pip install wandb\n",
    "    %pip install --upgrade \"kaleido==0.1.*\"\n",
    "    import kaleido\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import wandb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "from enum import Enum\n",
    "import plotly.express as px\n",
    "\n",
    "import dataclasses\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "class TempFileContext:\n",
    "    def __enter__(self):\n",
    "        self.tmp_file = tempfile.NamedTemporaryFile(suffix=\".jpeg\", delete=False)\n",
    "        self.tmp_filename = self.tmp_file.name\n",
    "        return self.tmp_filename\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.tmp_file.close()\n",
    "        os.remove(self.tmp_filename)\n",
    "\n",
    "# As per the DCGAN paper: All the weights are initialized from a zero centered normal distribution with standard deviation 0.02\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "class GeneratorUpSample(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, num_classes, features_g):\n",
    "        \"\"\"\n",
    "        channels_noise: The size of the input noise vector. This noise vector is a random input from which the generator begins the generation of a new sample.\n",
    "        channels_img: The number of output channels of the generator. This will typically be 1 for grayscale images or 3 for color (RGB) images.\n",
    "        num_classes: The number of distinct classes or labels that the generator should generate images for. This is used to form the one-hot vector of class labels, which is concatenated to the noise vector to provide the generator with information about the class of image to generate.\n",
    "        \"\"\"\n",
    "        # Conv2d formula => output_size = (input_size - 1) * stride - 2 * padding + kernel_size\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self.gen_block(channels_noise + num_classes, features_g * 4, kernel_size=7, stride=1, padding=0),  # output: (features_g*4) x 7 x 7 # Append class labels to input noise.\n",
    "            nn.Dropout(p=0.05),\n",
    "            self._block(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),  # output: (features_g*2) x 6 x 6\n",
    "            nn.Upsample(scale_factor=4, mode='bilinear'),  # output: (features_g*2) x 14 x 14\n",
    "            nn.Dropout(p=0.05),\n",
    "            self._block(features_g * 2, features_g, kernel_size=4, stride=2, padding=1),  # output: features_g x 14 x 14\n",
    "            nn.Upsample(scale_factor=5, mode='bilinear'),  # output: features_g x 28 x 28\n",
    "            nn.Dropout(p=0.05),\n",
    "            self._block(features_g, channels_img, kernel_size=7, stride=1, padding=2),  # output: channels_img x 28 x 28\n",
    "            nn.Tanh(),  # normalize [-1, 1]\n",
    "        )\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def gen_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    @autocast() # automatically applies precisions to different operations to speed up calculations\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "class GeneratorFractional(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, num_classes, features_g):\n",
    "        \"\"\"\n",
    "        channels_noise: The size of the input noise vector. This noise vector is a random input from which the generator begins the generation of a new sample.\n",
    "        channels_img: The number of output channels of the generator. This will typically be 1 for grayscale images or 3 for color (RGB) images.\n",
    "        num_classes: The number of distinct classes or labels that the generator should generate images for. This is used to form the one-hot vector of class labels, which is concatenated to the noise vector to provide the generator with information about the class of image to generate.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(channels_noise + num_classes, features_g * 8, kernel_size=4, stride=2, padding=1),  # output: (features_g*8) x 2 x 2\n",
    "            self._block(features_g * 8, features_g * 4, kernel_size=4, stride=2, padding=1),  # output: (features_g*4) x 4 x 4 \n",
    "            self._block(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),  # output: (features_g*2) x 8 x 8\n",
    "            self._block(features_g * 2, features_g, kernel_size=4, stride=2, padding=1),  # output: features_g x 16 x 16 \n",
    "            nn.ConvTranspose2d(features_g, channels_img, kernel_size=4, stride=2, padding=3),  # output: channels_img x 28 x 28\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    @autocast() # automatically applies precisions to different operations to speed up calculations\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "class GeneratorConv(nn.Module):\n",
    "    \"\"\"\n",
    "    GeneratorPixelShuffle\n",
    "    \"\"\"\n",
    "    def __init__(self, channels_noise, channels_img, num_classes, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Linear(channels_noise + num_classes, features_g * 4 * 7 * 7, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 4 * 7 * 7),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \"\"\"\n",
    "        In GANs, we start from a random noise vector in a latent space, but we want to generate 2D images. This transformation from a 1D noise vector to a 3D tensor is typically done using a dense layer, which learns to map the latent space effectively to the space of images during the training process.\n",
    "        Also, this fully connected layer allows the model to create complex mappings from the input noise vector to the output, which is essential when generating realistic images. The capacity of this layer can be adjusted via the number of neurons to control the complexity of the generated images.\n",
    "        \"\"\"\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(features_g * 4, features_g * 2, upscale_factor=2),  # output: (features_g*2) x 14 x 14 \n",
    "            self._block(features_g * 2, features_g, upscale_factor=2),  # output: features_g x 28 x 28 \n",
    "            nn.Conv2d(features_g, channels_img, kernel_size=4, stride=1, padding=3),  # output: channels_img x 28 x 28\n",
    "            # nn.Tanh()  # normalize inputs to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, upscale_factor):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=upscale_factor, mode='nearest'),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1)\n",
    "        x = self.initial(noise)\n",
    "        x = x.view(x.shape[0], -1, 7, 7)  # reshape into (batch_size, features_g * 4, 7, 7)\n",
    "        return self.gen(x)\n",
    "\n",
    "class DiscriminatorConv(nn.Module):\n",
    "    def __init__(self, channels_img, num_classes, num_kernels, kernel_dim, filters):\n",
    "        \"\"\"\n",
    "        channels_img: The number of input channels to the discriminator, corresponding to the number of channels in the images to be classified.\n",
    "        features_d: This is the base size of the feature maps in the discriminator. The number of neurons or nodes in each layer of the discriminator is a multiple of this base size.\n",
    "        num_classes: The number of distinct classes that the discriminator should be able to distinguish between. This is used to form the softmax output layer of the discriminator, which outputs a class probability distribution.\n",
    "        num_kernels and kernel_dim: These are parameters for the minibatch discrimination layer. The minibatch discrimination layer is designed to make the discriminator sensitive to the variety of samples within a minibatch, to encourage the generator to generate a variety of different samples. num_kernels is the number of unique patterns the layer can learn to identify, and kernel_dim is the size of these learned patterns.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(p=0.05),\n",
    "            self._block(filters, filters*2, 4, 2, 1),\n",
    "            nn.Dropout(p=0.05),\n",
    "        )\n",
    "        self.mbd = MinibatchDiscrimination(filters*2*7*7, num_kernels, kernel_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(filters*2*7*7 + num_kernels, filters*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(filters*8, 1 + num_classes),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mbd(x)\n",
    "        out = self.fc(x)\n",
    "        return out[:, 0], nn.functional.softmax(out[:, 1:], dim=1)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, num_classes, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(channels_noise + num_classes, features_g * 4 * 7 * 7, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 4 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 4 * 7 * 7, features_g * 2 * 14 * 14, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 2 * 14 * 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 2 * 14 * 14, features_g * 28 * 28, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 28 * 28),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 28 * 28, channels_img * 28 * 28),\n",
    "            # nn.Tanh()  # normalize inputs to [-1, 1]\n",
    "        )   \n",
    "    @autocast()\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1)\n",
    "        return self.net(noise).view(noise.shape[0], -1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, num_classes, num_kernels, kernel_dim, filters):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels_img * 28 * 28, filters * 2 * 14 * 14),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Linear(filters * 2 * 14 * 14, filters * 4 * 7 * 7),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(p=0.05),\n",
    "            MinibatchDiscrimination(filters * 4 * 7 * 7, num_kernels, kernel_dim),\n",
    "            nn.Linear(filters * 4 * 7 * 7 + num_kernels, filters * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(filters * 8, 1 + num_classes),\n",
    "        )\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.net(x.view(x.size(0), -1))\n",
    "        return x[:, 0], nn.functional.softmax(x[:, 1:], dim=1)\n",
    "\n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, input_features, num_kernels, kernel_dim):\n",
    "        super(MinibatchDiscrimination, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(input_features, num_kernels * kernel_dim))\n",
    "    def forward(self, x):\n",
    "        M = torch.matmul(x, self.T).view(-1, self.num_kernels, self.kernel_dim)\n",
    "        diffs = M.unsqueeze(0) - M.transpose(0, 1).unsqueeze(2)\n",
    "        abs_diffs = torch.sum(torch.abs(diffs), dim=2)\n",
    "        minibatch_features = torch.sum(torch.exp(-abs_diffs), dim=2).T\n",
    "        return torch.cat((x, minibatch_features), dim=1)\n",
    "\n",
    "class LR_Metric(Enum):\n",
    "    VALIDITY = 1\n",
    "    AGE = 2\n",
    "    \n",
    "class CustomDataLoader:\n",
    "    def __init__(self, X, Y, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.data = X.float().to(self.device)\n",
    "        self.targets = Y.to(self.device)\n",
    "        self.num_samples = len(self.data)\n",
    "    def __iter__(self):\n",
    "        self.indices = torch.randperm(self.num_samples, device=self.device)\n",
    "        self.idx = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self.idx >= self.num_samples:\n",
    "            raise StopIteration\n",
    "        indices = self.indices[self.idx:self.idx+self.batch_size]\n",
    "        batch_data = self.data[indices]\n",
    "        batch_targets = self.targets[indices]\n",
    "        self.idx += self.batch_size\n",
    "        return batch_data, batch_targets\n",
    "    def __len__(self):\n",
    "        return (self.num_samples + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "image_size = 28 * 28\n",
    "@dataclass\n",
    "class Config:\n",
    "    latent_dim: int = 100\n",
    "    batch_size: int = 256 * 2\n",
    "    num_epochs: int = 100\n",
    "    num_kernels: int = 10\n",
    "    kernel_dim: int = 3\n",
    "    d_learning_rate: float = 0.0002\n",
    "    g_learning_rate: float = 0.0002\n",
    "    lr_restarts: int = 5\n",
    "    min_lr: float = 1e-10\n",
    "    lambda_class: int = 1\n",
    "    replay_buffer_size: int = 1000\n",
    "    features_g: int = 4\n",
    "    features_d: int = 4\n",
    "    logEnd: bool = True\n",
    "    standardization: bool = True\n",
    "\n",
    "c = Config(logEnd=False)\n",
    "\n",
    "# normalize to [-1, 1]\n",
    "train_data = MNIST(root='data/MNIST',train=True,download=True)\n",
    "test_data = MNIST(root='data/MNIST', train=False, download=True)\n",
    "\n",
    "if c.standardization:\n",
    "    mean = train_data.data.float().mean()\n",
    "    std = train_data.data.float().std()\n",
    "    normalized_train_data = (train_data.data.float() - mean) / std\n",
    "    normalized_test_data = (test_data.data.float() - mean) / std\n",
    "else:\n",
    "    normalized_train_data = 2 * train_data.data.float() / 255 - 1\n",
    "    normalized_test_data = 2 * train_data.data.float() / 255 - 1\n",
    "\n",
    "preppedConfig = {}\n",
    "for k, v in dataclasses.asdict(c).items():\n",
    "    if dataclasses.is_dataclass(v):\n",
    "        preppedConfig[k] = dataclasses.asdict(v)\n",
    "    else:\n",
    "        preppedConfig[k] = v\n",
    "wandb.init(project=\"mnist-gan\", config=c)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # Because the performance of cuDNN algorithms to compute the convolution of different kernel sizes varies, \n",
    "    # the auto-tuner can run a benchmark to find the best algorithm (current algorithms are these, these, and these). \n",
    "    # It’s recommended to use turn on the setting when your input size doesn’t change often. If the input size changes often, \n",
    "    # the auto-tuner needs to benchmark too frequently, which might hurt the performance.\n",
    "\n",
    "train_loader = CustomDataLoader(normalized_train_data, train_data.targets, batch_size=c.batch_size, device=device)\n",
    "test_loader = CustomDataLoader(normalized_test_data, test_data.targets, batch_size=c.batch_size, device=device)\n",
    "\n",
    "# logging every epoch\n",
    "logsPerEpochNames = ['age', 'curGap', 'oldGap', 'oldScore', 'replayScore', 'replayValidity', 'oldValidity', 'accuracy', 'd_lr','g_lr']\n",
    "logsPerEpoch = {k: torch.zeros(c.num_epochs).to(device) for k in logsPerEpochNames}\n",
    "\n",
    "generator = Generator(c.latent_dim, 1, NUM_CLASSES, c.features_g).to(device)\n",
    "initialize_weights(generator)\n",
    "discriminator = Discriminator(1, NUM_CLASSES, c.num_kernels, c.kernel_dim, c.features_d).to(device)\n",
    "initialize_weights(discriminator)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=c.g_learning_rate, betas=(0.5, 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=c.d_learning_rate, betas=(0.5, 0.9))\n",
    "\n",
    "train_batches = len(train_loader)\n",
    "\n",
    "# logging every batch\n",
    "logsPerBatchNames = ['real_validity', 'fake_validity', 'd_fakeClassLoss', 'd_realClassLoss', 'd_fakeAccuracy', 'd_realAccuracy', 'd_loss_base', 'g_loss_base', 'g_fakeClassLoss']\n",
    "logsPerBatch = {k: torch.zeros(c.num_epochs * train_batches, device=device) for k in logsPerBatchNames}\n",
    "# logging is varied\n",
    "t_images = []\n",
    "\n",
    "class LearningRateScheduler:\n",
    "    def __init__(self, initial_lr, replay_buffer_size, total_batches, batch_size, METRIC=LR_Metric.VALIDITY):\n",
    "        self.initial_lr = initial_lr\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.total_batches = total_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.METRIC = METRIC\n",
    "        self.samplesPerBatch = int(np.ceil(replay_buffer_size / total_batches))\n",
    "        self.filledIndex = 0\n",
    "        self.oldFake_validity = torch.zeros(self.replay_buffer_size, device=device, dtype=torch.float16)\n",
    "        self.oldReal_validity = torch.zeros(self.replay_buffer_size, device=device, dtype=torch.float16)\n",
    "        self.oldFake_validities = torch.zeros(self.replay_buffer_size, device=device, dtype=torch.float16)\n",
    "        # self.oldFake_validity = torch.zeros(self.replay_buffer_size, device=device) #, dtype=torch.float16)\n",
    "        # self.oldReal_validity = torch.zeros(self.replay_buffer_size, device=device) #, dtype=torch.float16)\n",
    "        # self.oldFake_validities = torch.zeros(self.replay_buffer_size, device=device) #, dtype=torch.float16)\n",
    "        self.z_replay = torch.zeros(self.replay_buffer_size, c.latent_dim + NUM_CLASSES, device=device)\n",
    "        self.age = torch.zeros(self.replay_buffer_size, device=device)\n",
    "        self.kickTopPercent = 0.25\n",
    "        self.openIndexes = torch.ones(self.replay_buffer_size, device=device)\n",
    "        self.real_validity_total = torch.zeros(1, device=device)\n",
    "        self.fake_validity_total = torch.zeros(1, device=device)\n",
    "        self.numSamples = 0\n",
    "\n",
    "    def fillReplayBuffer(self, real_validity, real_validities, fake_validity, fake_validities, z):\n",
    "        \"\"\"\n",
    "        samples (amouting to replay_buffer_size) will be evenly provided by all batches to fill the replay buffer in 1 epoch\n",
    "        \"\"\"\n",
    "        with torch.no_grad() and torch.cuda.amp.autocast():\n",
    "            self.real_validity_total += real_validities.sum()\n",
    "            self.fake_validity_total += fake_validities.sum()\n",
    "            self.numSamples += len(z)\n",
    "            openings = (self.openIndexes > 0).sum().item()\n",
    "            numSamples = len(z)  \n",
    "            if self.filledIndex < self.replay_buffer_size: \n",
    "                # start filling the buffer front to back, only fill self.samplesPerBatch to prevent, the early batches from dominanting the replay buffer\n",
    "                remaining = self.replay_buffer_size - self.filledIndex\n",
    "                numSelected = np.min([remaining, numSamples, self.samplesPerBatch])\n",
    "                selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "                indexes = torch.arange(self.filledIndex, self.filledIndex + len(selected))\n",
    "                self.filledIndex += len(selected)\n",
    "            elif openings:\n",
    "                # randomly select samples to fill the openIndexes in the replay buffer\n",
    "                indexes = torch.nonzero(self.openIndexes).squeeze()\n",
    "                numSelected = np.min([openings, numSamples, self.samplesPerBatch])\n",
    "                selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "                indexes = np.random.choice(indexes.numel(), numSelected, replace=False)\n",
    "            else:\n",
    "                return\n",
    "            self.oldFake_validity[indexes] = fake_validity.repeat(len(indexes))\n",
    "            self.oldReal_validity[indexes] = real_validity.repeat(len(indexes))\n",
    "            self.oldFake_validities[indexes] = fake_validities[selected].squeeze()\n",
    "            self.z_replay[indexes,:] = z[selected]\n",
    "            self.age[indexes] = 0\n",
    "            self.openIndexes[indexes] = 0\n",
    "\n",
    "    def plotReplayValidities(self):\n",
    "        i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(x=self.oldReal_validity[i_replays].cpu().numpy(), name=\"real\"))\n",
    "        fig.add_trace(go.Histogram(x=self.oldFake_validity[i_replays].cpu().numpy(), name=\"fake\"))\n",
    "        fig.update_layout(barmode='overlay', title=\"saved validity scores histogram\")\n",
    "        fig.show()\n",
    "\n",
    "    def update_learning_rate(self, epoch, d, g):\n",
    "        with torch.no_grad():\n",
    "            i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "            z_replay = self.z_replay[i_replays]\n",
    "            z_replay = z_replay.view(len(z_replay), c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "            fake_replay = g(z_replay)\n",
    "            replayFake_validities, _ = d(fake_replay)\n",
    "            replayFake_validities = replayFake_validities.squeeze()\n",
    "    \n",
    "            # if gaps are negatives then discriminator then fake images are getting higher validity scores than real ones\n",
    "            oldGap = (self.oldReal_validity[i_replays] - self.oldFake_validity[i_replays]).mean()\n",
    "            curGap = self.real_validity_total / self.numSamples - self.fake_validity_total / self.numSamples\n",
    "            # positive - smaller positive\n",
    "\n",
    "            replayScores = replayFake_validities - curGap.repeat(len(i_replays))\n",
    "            oldScores = self.oldFake_validities[i_replays] - oldGap.repeat(len(i_replays))\n",
    "            values = [ self.age[i_replays].mean(), curGap, oldGap, replayScores.mean(), oldScores.mean(), replayFake_validities.mean(), self.oldFake_validities[i_replays].mean()]\n",
    "            for name, value in zip(['age', 'curGap', 'oldGap', 'replayScore', 'oldScore', 'replayValidity', 'oldValidity'], values):\n",
    "                logsPerEpoch[name][epoch] = value\n",
    "               \n",
    "            if self.METRIC.value == LR_Metric.VALIDITY.value:\n",
    "                metric = replayFake_validities.squeeze()\n",
    "            elif self.METRIC.value == LR_Metric.AGE.value:\n",
    "                metric = self.age[i_replays].squeeze()\n",
    "                raise NotImplementedError(\"needs to be adjusted\")\n",
    "            else:\n",
    "                raise Exception(\"Invalid metric\")\n",
    "            # Kick out top 10% of the replay buffer based on replayScores scores, lowest to highest, drop the highest\n",
    "            i_highestMetric = torch.argsort(metric)[-int(np.ceil(self.kickTopPercent * self.replay_buffer_size)):]\n",
    "            self.openIndexes[i_highestMetric] = 1\n",
    "\n",
    "            # kick out first half for testing\n",
    "            # self.openIndexes[:int(self.replay_buffer_size/2)] = torch.ones(int(self.replay_buffer_size/2)).to(device)\n",
    "\n",
    "            self.age += 1\n",
    "\n",
    "lr_scheduler_trial = LearningRateScheduler(initial_lr=0.001, replay_buffer_size=c.replay_buffer_size, total_batches=train_batches, batch_size=c.batch_size)\n",
    "d_lr_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(discriminator_optimizer, T_0=int(c.num_epochs/c.lr_restarts), T_mult=1, eta_min=c.min_lr)\n",
    "\n",
    "# d_lr_scheduler = lr_scheduler.\n",
    "classCriterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def createGridFakeImages(epoch=0, cubeSide=3, show=False, step=None, log=True):\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                        horizontal_spacing=0.01, \n",
    "                        shared_yaxes=True)\n",
    "    numImages = torch.tensor([cubeSide**2], device=device)\n",
    "    # Generate and plot fake images with labels\n",
    "    labels = torch.randint(0, 10, (numImages,), device=device)\n",
    "    labels_one_hot = torch.zeros(numImages, 10, device=device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(numImages, c.latent_dim, device=device)\n",
    "        g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "        g_input = g_input.view(numImages, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "        fake_images = generator(g_input)\n",
    "        # fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "        # g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "    fig = make_subplots(rows=cubeSide, cols=cubeSide, \n",
    "                        horizontal_spacing = 0.025,\n",
    "                        vertical_spacing = 0.04,\n",
    "                        subplot_titles=[str(label.item()) for label in labels])\n",
    "    fake_images = fake_images.squeeze().cpu().numpy()\n",
    "    for i in range(numImages):\n",
    "        row = int(i/cubeSide) + 1\n",
    "        col = int(i%cubeSide) + 1\n",
    "        imageFlipped = np.flip(fake_images[i], 0)\n",
    "        fig.add_trace(go.Heatmap(z=imageFlipped, \n",
    "                                colorscale='Greys',), row=row, col=col)\n",
    "    fig.update_layout(title_text=\"Generated Images epoch: \" + str(epoch), \n",
    "                    margin=dict(l=0, r=0, t=60, b=0),\n",
    "                    height=400, width=400, showlegend=False)\n",
    "    fig.update_traces(showscale=False)\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if log:\n",
    "        if step is None:\n",
    "            raise Exception(\"step must be provided when logging an image\")\n",
    "        # Convert the figure to a JPEG image and log using wandb\n",
    "        image_bytes = pio.to_image(fig, format='jpeg')\n",
    "        if not c.logEnd:\n",
    "            with TempFileContext() as tmp_filename:\n",
    "                with open(tmp_filename, 'wb') as tmp_file:\n",
    "                    tmp_file.write(image_bytes)\n",
    "                wandb.log(wandb.Image(tmp_filename), step=step)\n",
    "        else:\n",
    "            t_images.append((image_bytes, step))\n",
    "\n",
    "def check_frozen_parameters(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            print(f\"Parameter '{name}' is frozen!\")\n",
    "\n",
    "scaler = GradScaler()\n",
    "# GradScaler with PyTorch's autocast prevents gradient underflow in mixed precision training.\n",
    "# It achieves this by scaling up the loss before backward pass to keep float16 gradients from vanishing.\n",
    "# After gradients are computed, they are scaled back before the optimizer updates the model weights.\n",
    "\n",
    "if not c.logEnd:\n",
    "  wandb.watch([generator, discriminator], log=\"all\")\n",
    "\n",
    "for epoch in range(c.num_epochs):\n",
    "    correct, total = 0, 0\n",
    "    epoch_metrics = {}\n",
    "    for i, (real_images, labels) in enumerate(train_loader):\n",
    "        batch_metrics = {}\n",
    "        # s_time = time.time()\n",
    "        # print(f\"Epoch {epoch}/{num_epochs} Batch {i}/{total_steps}\")\n",
    "        _batch_size = real_images.size(0)\n",
    "        real_images = real_images.unsqueeze(1)\n",
    "        labels_one_hot = torch.zeros(_batch_size, NUM_CLASSES, device=device).scatter_(1, labels.view(_batch_size, 1), 1).to(device)\n",
    "\n",
    "        # train generator\n",
    "        # Setting gradients to zeroes by model.zero_grad() or optimizer.zero_grad() would execute memset for all parameters and update gradients with reading and writing operations. \n",
    "        # However, setting the gradients as None would not execute memset and would update gradients with only writing operations.\n",
    "        generator_optimizer.zero_grad(set_to_none=True)\n",
    "        z = torch.randn(_batch_size, c.latent_dim).to(device)\n",
    "        g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "        g_input = g_input.view(_batch_size, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "        fake_images = generator(g_input)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "        # g_loss should minimize the difference in predicting classes among the same classes\n",
    "        g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        # WGAN-GP\n",
    "        # g_loss = -torch.mean(fake_validities) + g_fakeClassLoss * lambda_class\n",
    "        d_logits_gen = fake_validities.view(-1)\n",
    "        # LSGAN\n",
    "        g_loss_base = criterion(d_logits_gen, torch.ones_like(d_logits_gen))\n",
    "        g_loss = g_loss_base + g_fakeClassLoss * c.lambda_class\n",
    "        # g_loss.backward()\n",
    "        # generator_optimizer.step()\n",
    "        scaler.scale(g_loss).backward()\n",
    "        scaler.step(generator_optimizer)\n",
    "        \n",
    "        # train discriminator\n",
    "        discriminator_optimizer.zero_grad(set_to_none=True)\n",
    "        real_validities, d_realClass = discriminator(real_images)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images.clone().detach())\n",
    "\n",
    "        loss_disc_real = criterion(real_validities, torch.ones_like(real_validities))\n",
    "        loss_disc_fake = criterion(fake_validities, -torch.ones_like(fake_validities)) # modified to -1 from normal LSGAN 0 target\n",
    "        # LSGAN\n",
    "        d_loss_base = (loss_disc_real + loss_disc_fake) / 2\n",
    "        \n",
    "        # gradient_penalty = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "        # d_loss = -torch.mean(real_validities) + torch.mean(fake_validities) + lambda_gp * gradient_penalty\n",
    "        d_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        d_fakeAccuracy = (d_fakeClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_realClassLoss = classCriterion(d_realClass, labels_one_hot)\n",
    "        d_realAccuracy = (d_realClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_loss = d_loss_base + (d_fakeClassLoss + d_realClassLoss) / 2\n",
    "        # d_loss.backward()\n",
    "        # discriminator_optimizer.step()\n",
    "        scaler.scale(d_loss).backward()\n",
    "        scaler.step(discriminator_optimizer)\n",
    "\n",
    "        # print(\"g_loss_base: \", g_loss_base.item(), \"g_fakeClassLoss: \", g_fakeClassLoss.item(), \"d_loss_base: \", d_loss_base.item(), \"d_fakeClassLoss: \", d_fakeClassLoss.item(), \"d_realClassLoss: \", d_realClassLoss.item())\n",
    "\n",
    "        # if i == train_batches - 1:\n",
    "        #     fig = px.imshow(fake_images[0].detach().squeeze().cpu().numpy(), color_continuous_scale='Greys')\n",
    "        #     fig.show()\n",
    "        #     fig = px.imshow(real_images[0].detach().squeeze().cpu().numpy(), color_continuous_scale='Greys')\n",
    "        #     fig.show()\n",
    "\n",
    "        correct += (real_validities > 0).sum().item() + (fake_validities < 0).sum().item()\n",
    "        total += len(real_validities) + len(fake_validities)\n",
    "        # if (i+1) % 200 == 0:\n",
    "        #     print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{train_batches}], d_loss: {d_loss_base.item():.4f}, g_loss: {g_loss.item():.4f}\")\n",
    "        g_input = g_input.view(_batch_size, c.latent_dim + NUM_CLASSES)\n",
    "        real_validity = real_validities.mean()\n",
    "        fake_validity = fake_validities.mean()\n",
    "        lr_scheduler_trial.fillReplayBuffer(real_validity, real_validities, fake_validity, fake_validities, g_input)\n",
    "        # print(\"lr_scheduler_trial: \", time.time() - s_time)\n",
    "        i_step = epoch * train_batches + i\n",
    "        values = [real_validity, fake_validity, d_fakeClassLoss, d_realClassLoss, d_fakeAccuracy, d_realAccuracy, d_loss_base, g_loss_base, g_fakeClassLoss]\n",
    "        for name, value in zip(logsPerBatchNames, values):\n",
    "            logsPerBatch[name][i_step] = value\n",
    "\n",
    "        if not c.logEnd and i != train_batches - 1:\n",
    "            batch_metrics.update({name: value.item() for name, value in zip(logsPerBatchNames, values)})\n",
    "            wandb.log(batch_metrics, step=i_step)\n",
    "\n",
    "        scaler.update()\n",
    "    \n",
    "    check_frozen_parameters(discriminator)\n",
    "    check_frozen_parameters(generator)\n",
    "\n",
    "    d_lr_scheduler.step()\n",
    "    accuracy = correct / total\n",
    "\n",
    "    lr_scheduler_trial.update_learning_rate(epoch, discriminator, generator)\n",
    "\n",
    "    logsPerEpoch['accuracy'][epoch] = accuracy\n",
    "    logsPerEpoch['g_lr'][epoch] = generator_optimizer.param_groups[0]['lr']\n",
    "    logsPerEpoch['d_lr'][epoch] = discriminator_optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if not c.logEnd:\n",
    "        epoch_metrics.update({name: logsPerEpoch[name][epoch].item() for name in logsPerEpochNames})\n",
    "        epoch_metrics.update(batch_metrics)\n",
    "        wandb.log(epoch_metrics, step=i_step)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{c.num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, accuracy: {accuracy:.4f}, d_lr: {discriminator_optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    # if epoch % 20 == 0:\n",
    "    createGridFakeImages(epoch=epoch,cubeSide=5, show=True, log=True, step=i_step)\n",
    "\n",
    "for name in logsPerEpochNames:\n",
    "    logsPerEpoch[name] = logsPerEpoch[name].cpu().detach().numpy()\n",
    "for name in logsPerBatchNames:\n",
    "    logsPerBatch[name] = logsPerBatch[name].cpu().detach().numpy()\n",
    "\n",
    "def wandbLogAtEnd():\n",
    "    imageIndex = 0\n",
    "    _t_images = t_images.copy()\n",
    "    for epoch in range(c.num_epochs):\n",
    "        for i in range(train_batches):\n",
    "            step = epoch * train_batches + i\n",
    "            if i != train_batches - 1:\n",
    "                metrics = {name : logsPerBatch[name][step] for name in logsPerBatchNames}\n",
    "                wandb.log(metrics, step=step)\n",
    "        epochMetrics = {name : logsPerEpoch[name][epoch] for name in logsPerEpochNames}\n",
    "        epochMetrics.update(metrics)\n",
    "        if len(_t_images) and _t_images[0][1] == step:\n",
    "            with TempFileContext() as tmp_filename:\n",
    "                image_bytes = _t_images[0][0]\n",
    "                with open(tmp_filename, 'wb') as tmp_file:\n",
    "                    tmp_file.write(image_bytes)\n",
    "                epochMetrics['generator_output'] = wandb.Image(tmp_filename)\n",
    "                wandb.log(epochMetrics, step=step)\n",
    "            _t_images = _t_images[1:]\n",
    "        else:\n",
    "            wandb.log(epochMetrics, step=step)\n",
    "    wandb.finish()\n",
    "\n",
    "if c.logEnd:\n",
    "    wandbLogAtEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0310, -0.0364, -0.0615, -0.0573, -0.0472, -0.0359, -0.0599, -0.0405,\n",
       "         -0.0438, -0.0354], grad_fn=<SelectBackward0>),\n",
       " tensor([[0.0967, 0.0990, 0.1055, 0.0961, 0.0938, 0.0966, 0.1057, 0.0964, 0.1057,\n",
       "          0.1046],\n",
       "         [0.0985, 0.0981, 0.1069, 0.0968, 0.0941, 0.0944, 0.1047, 0.0951, 0.1063,\n",
       "          0.1051],\n",
       "         [0.0980, 0.0979, 0.1031, 0.0984, 0.0943, 0.0959, 0.1049, 0.0966, 0.1076,\n",
       "          0.1034],\n",
       "         [0.0979, 0.0967, 0.1049, 0.0973, 0.0925, 0.0963, 0.1044, 0.0983, 0.1086,\n",
       "          0.1030],\n",
       "         [0.0982, 0.0966, 0.1048, 0.0977, 0.0932, 0.0963, 0.1048, 0.0962, 0.1095,\n",
       "          0.1027],\n",
       "         [0.0996, 0.0965, 0.1031, 0.0987, 0.0963, 0.0947, 0.1062, 0.0967, 0.1072,\n",
       "          0.1011],\n",
       "         [0.0985, 0.0955, 0.1052, 0.0963, 0.0945, 0.0967, 0.1029, 0.0972, 0.1095,\n",
       "          0.1038],\n",
       "         [0.0987, 0.0956, 0.1053, 0.0965, 0.0932, 0.0969, 0.1046, 0.0974, 0.1069,\n",
       "          0.1050],\n",
       "         [0.1003, 0.0939, 0.1051, 0.0967, 0.0951, 0.0952, 0.1031, 0.0965, 0.1082,\n",
       "          0.1058],\n",
       "         [0.0979, 0.0985, 0.1028, 0.0957, 0.0932, 0.0953, 0.1070, 0.0944, 0.1099,\n",
       "          0.1051]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, num_classes, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(channels_noise + num_classes, features_g * 4 * 7 * 7, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 4 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 4 * 7 * 7, features_g * 2 * 14 * 14, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 2 * 14 * 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 2 * 14 * 14, features_g * 28 * 28, bias=False),\n",
    "            nn.BatchNorm1d(features_g * 28 * 28),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_g * 28 * 28, channels_img * 28 * 28),\n",
    "            # nn.Tanh()  # normalize inputs to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        noise = noise.view(noise.shape[0], -1)\n",
    "        return self.net(noise).view(noise.shape[0], -1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, num_classes, num_kernels, kernel_dim, filters):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels_img * 28 * 28, filters * 2 * 14 * 14),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(p=0.05),\n",
    "            nn.Linear(filters * 2 * 14 * 14, filters * 4 * 7 * 7),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(p=0.05),\n",
    "            MinibatchDiscrimination(filters * 4 * 7 * 7, num_kernels, kernel_dim),\n",
    "            nn.Linear(filters * 4 * 7 * 7 + num_kernels, filters * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(filters * 8, 1 + num_classes),\n",
    "        )\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.net(x.view(x.size(0), -1))\n",
    "        return x[:, 0], nn.functional.softmax(x[:, 1:], dim=1)\n",
    "\n",
    "generator = Generator(c.latent_dim,1, NUM_CLASSES, 32).to(device)\n",
    "numImages = 10\n",
    "labels = torch.randint(0, 10, (numImages,), device=device)\n",
    "labels_one_hot = torch.zeros(numImages, 10, device=device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "z = torch.randn(numImages, c.latent_dim, device=device)\n",
    "g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "g_input = g_input.view(numImages, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "fake_images = generator(g_input)\n",
    "fake_images.shape\n",
    "\n",
    "discriminator = Discriminator(1, NUM_CLASSES, 5, 3, 32).to(device)\n",
    "discriminator(fake_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numImages = torch.tensor([2000]).to(device)\n",
    "# Generate and plot fake images with labels\n",
    "labels = torch.randint(0, 10, (numImages,)).to(device)\n",
    "labels_one_hot = torch.zeros(numImages, 10).to(device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(numImages, c.latent_dim).to(device)\n",
    "    g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "    g_input = g_input.view(numImages, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "    fake_images = generator(g_input)\n",
    "    fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "    g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "\n",
    "fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "label_text = [str(label.item()) for label in labels]\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(numImages):\n",
    "    plt.subplot(int(numImages**0.5), int(numImages**0.5), i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(label_text[i], fontsize=10)\n",
    "    plt.imshow(fake_images[i].cpu().squeeze(), cmap='gray')\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.suptitle(\"Generated Images epoch: \" + str(epoch), fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# # save plotly\n",
    "\n",
    "# # Save the figure to a file\n",
    "# image_path = \"image.jpg\"\n",
    "# plt.savefig(image_path)\n",
    "# # Convert the saved image file to wandb.Image and log using wandb\n",
    "# with open(image_path, \"rb\") as img_file:\n",
    "#     img_data = img_file.read()\n",
    "#     image = Image.open(io.BytesIO(img_data))\n",
    "#     wandb.log({\"generator_output\": wandb.Image(image)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an optimizer\n",
    "initial_lr = 0.001\n",
    "min_lr = 0.000001\n",
    "optimizer = torch.optim.SGD([torch.randn(1, requires_grad=True)], lr= initial_lr)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 100\n",
    "cycles = 4\n",
    "# Learning rate schedulers\n",
    "cosineAnnealingWarmRestarts = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(c.num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "schedulers = {\n",
    "    # \"LambdaLR\": lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "    # \"MultiplicativeLR\": lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95),\n",
    "    # \"StepLR\": lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1),\n",
    "    # \"MultiStepLR\": lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1),\n",
    "    # \"ConstantLR\": lr_scheduler.ConstantLR(optimizer),\n",
    "    # \"LinearLR\" : lr_scheduler.LinearLR(optimizer),\n",
    "    # \"ExponentialLR\": lr_scheduler.ExponentialLR(optimizer, gamma=0.1),\n",
    "    # \"PolynomialLR\": lr_scheduler.PolynomialLR(optimizer,total_iters=4, power=1.0),\n",
    "    # \"CosineAnnealingLR\": lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0),\n",
    "    \"ChainedScheduler\" : lr_scheduler.ChainedScheduler([lr_scheduler.ConstantLR(optimizer, total_iters=10), cosineAnnealingWarmRestarts]),\n",
    "    # \"SequentialLR\": lr_scheduler.SequentialLR(optimizer, schedulers=[lr_scheduler.ConstantLR(optimizer, factor=0.1, total_iters=2), lr_scheduler.ExponentialLR(optimizer, gamma=0.9)], milestones=[2]),\n",
    "    # \"ReduceLROnPlateau\": lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10),\n",
    "    # \"CyclicLR\": lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=1, step_size_up=5, mode='triangular2'),\n",
    "    # \"OneCycleLR\": lr_scheduler.OneCycleLR(optimizer, max_lr=1, total_steps=num_epochs),\n",
    "    # \"CosineAnnealingWarmRestarts\": lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "}\n",
    "\n",
    "# Create a plot for each scheduler\n",
    "for name, scheduler in schedulers.items():\n",
    "    lrs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.step()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        if name != \"ReduceLROnPlateau\":\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step(epoch)  # Assume loss is decreasing with epoch for this example\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lrs)\n",
    "    plt.title(name)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
