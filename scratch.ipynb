{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an optimizer\n",
    "initial_lr = 0.001\n",
    "min_lr = 0.000001\n",
    "optimizer = torch.optim.SGD([torch.randn(1, requires_grad=True)], lr= initial_lr)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 100\n",
    "cycles = 4\n",
    "# Learning rate schedulers\n",
    "cosineAnnealingWarmRestarts = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "schedulers = {\n",
    "    # \"LambdaLR\": lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "    # \"MultiplicativeLR\": lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95),\n",
    "    # \"StepLR\": lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1),\n",
    "    # \"MultiStepLR\": lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1),\n",
    "    # \"ConstantLR\": lr_scheduler.ConstantLR(optimizer),\n",
    "    # \"LinearLR\" : lr_scheduler.LinearLR(optimizer),\n",
    "    # \"ExponentialLR\": lr_scheduler.ExponentialLR(optimizer, gamma=0.1),\n",
    "    # \"PolynomialLR\": lr_scheduler.PolynomialLR(optimizer,total_iters=4, power=1.0),\n",
    "    # \"CosineAnnealingLR\": lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0),\n",
    "    \"ChainedScheduler\" : lr_scheduler.ChainedScheduler([lr_scheduler.ConstantLR(optimizer, total_iters=10), cosineAnnealingWarmRestarts]),\n",
    "    # \"SequentialLR\": lr_scheduler.SequentialLR(optimizer, schedulers=[lr_scheduler.ConstantLR(optimizer, factor=0.1, total_iters=2), lr_scheduler.ExponentialLR(optimizer, gamma=0.9)], milestones=[2]),\n",
    "    # \"ReduceLROnPlateau\": lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10),\n",
    "    # \"CyclicLR\": lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=1, step_size_up=5, mode='triangular2'),\n",
    "    # \"OneCycleLR\": lr_scheduler.OneCycleLR(optimizer, max_lr=1, total_steps=num_epochs),\n",
    "    # \"CosineAnnealingWarmRestarts\": lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "}\n",
    "\n",
    "# Create a plot for each scheduler\n",
    "for name, scheduler in schedulers.items():\n",
    "    lrs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.step()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        if name != \"ReduceLROnPlateau\":\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step(epoch)  # Assume loss is decreasing with epoch for this example\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lrs)\n",
    "    plt.title(name)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in ./venvDev/lib/python3.8/site-packages (0.15.4)\n",
      "Requirement already satisfied: setproctitle in ./venvDev/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: typing-extensions in ./venvDev/lib/python3.8/site-packages (from wandb) (4.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (4.23.2)\n",
      "Requirement already satisfied: PyYAML in ./venvDev/lib/python3.8/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in ./venvDev/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (3.1.31)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: pathtools in ./venvDev/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (1.25.1)\n",
      "Requirement already satisfied: setuptools in ./venvDev/lib/python3.8/site-packages (from wandb) (56.0.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./venvDev/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: six>=1.4.0 in ./venvDev/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./venvDev/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venvDev/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venvDev/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venvDev/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venvDev/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./venvDev/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/mnann/Documents/Code/AuthenticCursor/venvDev/bin/python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MNIST' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 168\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)):\n\u001b[1;32m    167\u001b[0m     image, label \u001b[39m=\u001b[39m dataset[i]\n\u001b[0;32m--> 168\u001b[0m     dataset[i] \u001b[39m=\u001b[39m (image\u001b[39m.\u001b[39mto(device), label)\n\u001b[1;32m    169\u001b[0m \u001b[39m# indices = torch.arange(10000)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m# dataset = data_utils.Subset(dataset, indices)\u001b[39;00m\n\u001b[1;32m    171\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MNIST' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %pip install wandb\n",
    "    %pip install --upgrade \"kaleido==0.1.*\"\n",
    "    import kaleido\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import wandb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import time\n",
    "from enum import Enum\n",
    "\n",
    "import dataclasses\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "class TempFileContext:\n",
    "    def __enter__(self):\n",
    "        self.tmp_file = tempfile.NamedTemporaryFile(suffix=\".jpeg\", delete=False)\n",
    "        self.tmp_filename = self.tmp_file.name\n",
    "        return self.tmp_filename\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.tmp_file.close()\n",
    "        os.remove(self.tmp_filename)\n",
    "\n",
    "# As per the DCGAN paper: All the weights are initialized from a zero centered normal distribution with standard deviation 0.02\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, num_classes):\n",
    "        \"\"\"\n",
    "        channels_noise: The size of the input noise vector. This noise vector is a random input from which the generator begins the generation of a new sample.\n",
    "        channels_img: The number of output channels of the generator. This will typically be 1 for grayscale images or 3 for color (RGB) images.\n",
    "        num_classes: The number of distinct classes or labels that the generator should generate images for. This is used to form the one-hot vector of class labels, which is concatenated to the noise vector to provide the generator with information about the class of image to generate.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.channels_noise = channels_noise\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            self.gen_block(channels_noise + num_classes, 256, kernel_size=7, stride=1, padding=0), # Append class labels to input noise.\n",
    "            self.gen_block(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose2d(128, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def gen_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    @autocast() # automatically applies precisions to different operations to speed up calculations\n",
    "    def forward(self, z):\n",
    "        return self.gen(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, num_classes, num_kernels, kernel_dim):\n",
    "        \"\"\"\n",
    "        channels_img: The number of input channels to the discriminator, corresponding to the number of channels in the images to be classified.\n",
    "        features_d: This is the base size of the feature maps in the discriminator. The number of neurons or nodes in each layer of the discriminator is a multiple of this base size.\n",
    "        num_classes: The number of distinct classes that the discriminator should be able to distinguish between. This is used to form the softmax output layer of the discriminator, which outputs a class probability distribution.\n",
    "        num_kernels and kernel_dim: These are parameters for the minibatch discrimination layer. The minibatch discrimination layer is designed to make the discriminator sensitive to the variety of samples within a minibatch, to encourage the generator to generate a variety of different samples. num_kernels is the number of unique patterns the layer can learn to identify, and kernel_dim is the size of these learned patterns.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, 32, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            self._block(32, 64, 4, 2, 1),\n",
    "        )\n",
    "        self.mbd = MinibatchDiscrimination(64*7*7, num_kernels, kernel_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*7*7 + num_kernels, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1 + num_classes),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mbd(x)\n",
    "        out = self.fc(x)\n",
    "        return out[:, 0], nn.functional.softmax(out[:, 1:], dim=1)\n",
    "\n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, input_features, num_kernels, kernel_dim):\n",
    "        super(MinibatchDiscrimination, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(input_features, num_kernels * kernel_dim))\n",
    "    def forward(self, x):\n",
    "        M = torch.matmul(x, self.T).view(-1, self.num_kernels, self.kernel_dim)\n",
    "        diffs = M.unsqueeze(0) - M.transpose(0, 1).unsqueeze(2)\n",
    "        abs_diffs = torch.sum(torch.abs(diffs), dim=2)\n",
    "        minibatch_features = torch.sum(torch.exp(-abs_diffs), dim=2).T\n",
    "        return torch.cat((x, minibatch_features), dim=1)\n",
    "\n",
    "class LR_Metric(Enum):\n",
    "    VALIDITY = 1\n",
    "    AGE = 2\n",
    "    \n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size, device):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.data = self.dataset.data.float().to(self.device)\n",
    "        self.targets = self.dataset.targets.to(self.device)\n",
    "        self.num_samples = len(self.data)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.indices = torch.randperm(self.num_samples, device=self.device)\n",
    "        self.idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.idx >= self.num_samples:\n",
    "            raise StopIteration\n",
    "\n",
    "        indices = self.indices[self.idx:self.idx+self.batch_size]\n",
    "        batch_data = self.data[indices]\n",
    "        batch_targets = self.targets[indices]\n",
    "\n",
    "        self.idx += self.batch_size\n",
    "\n",
    "        return batch_data, batch_targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_samples + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_data = MNIST(root='./dataset/minst/',train=True,download=True,transform=transform)\n",
    "test_data = MNIST(root='./dataset/minst/', train=False, download=True, transform=transform)\n",
    "\n",
    "# Hyperparameters\n",
    "image_size = 28 * 28\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    latent_dim: int = 100\n",
    "    batch_size: int = 256\n",
    "    num_epochs: int = 100\n",
    "    num_kernels: int = 10\n",
    "    kernel_dim: int = 3\n",
    "    learning_rate: float = 0.0002\n",
    "    lr_restarts: int = 5\n",
    "    min_lr: float = 1e-10\n",
    "    lambda_class: int = 1\n",
    "    replay_buffer_size: int = 1000\n",
    "\n",
    "c = Config()\n",
    "preppedConfig = {}\n",
    "for k, v in dataclasses.asdict(c).items():\n",
    "    if dataclasses.is_dataclass(v):\n",
    "        preppedConfig[k] = dataclasses.asdict(v)\n",
    "    else:\n",
    "        preppedConfig[k] = v\n",
    "wandb.init(project=\"mnist-gan\", config=c)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # Because the performance of cuDNN algorithms to compute the convolution of different kernel sizes varies, \n",
    "    # the auto-tuner can run a benchmark to find the best algorithm (current algorithms are these, these, and these). \n",
    "    # It’s recommended to use turn on the setting when your input size doesn’t change often. If the input size changes often, \n",
    "    # the auto-tuner needs to benchmark too frequently, which might hurt the performance.\n",
    "\n",
    "train_loader = CustomDataLoader(train_data, batch_size=c.batch_size, device=device)\n",
    "test_loader = CustomDataLoader(test_data, batch_size=c.batch_size, device=device)\n",
    "\n",
    "# logging every epoch\n",
    "t_age = torch.zeros(num_epochs).to(device)\n",
    "t_curGap = torch.zeros(num_epochs).to(device)\n",
    "t_oldGap = torch.zeros(num_epochs).to(device)\n",
    "t_oldScore = torch.zeros(num_epochs).to(device)\n",
    "t_replayScore = torch.zeros(num_epochs).to(device)\n",
    "t_replayValidity = torch.zeros(num_epochs).to(device)\n",
    "t_oldValidity = torch.zeros(num_epochs).to(device)\n",
    "t_accuracy = torch.zeros(num_epochs).to(device)\n",
    "t_d_lr = torch.zeros(num_epochs).to(device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "dataset = MNIST('data/MNIST', train=True, download=True, transform=transform)\n",
    "# Move the tensors in the dataset to the GPU\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "generator = Generator(c.latent_dim, 1, NUM_CLASSES).to(device)\n",
    "initialize_weights(generator)\n",
    "discriminator = Discriminator(1, NUM_CLASSES, c.num_kernels, c.kernel_dim).to(device)\n",
    "initialize_weights(discriminator)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=c.learning_rate, betas=(0.5, 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=c.learning_rate, betas=(0.5, 0.9))\\\n",
    "\n",
    "train_batches = len(train_loader)\n",
    "\n",
    "# logging every batch\n",
    "t_real_validity = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_fake_validity = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_d_fakeClassLoss = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_d_realClassLoss = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_d_fakeAccuracy = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_d_realAccuracy = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_d_loss_base = torch.zeros(num_epochs * train_batches).to(device)\n",
    "t_g_loss_base = torch.zeros(num_epochs * train_batches).to(device)\n",
    "# logging is varied\n",
    "t_images = []\n",
    "\n",
    "class LearningRateScheduler:\n",
    "    def __init__(self, initial_lr, replay_buffer_size, total_batches, batch_size, METRIC=LR_Metric.VALIDITY):\n",
    "        self.initial_lr = initial_lr\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.total_batches = total_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.METRIC = METRIC\n",
    "        self.samplesPerBatch = int(np.ceil(replay_buffer_size / total_batches))\n",
    "        self.filledIndex = 0\n",
    "        self.oldFake_validity = torch.zeros(self.replay_buffer_size, device=device)\n",
    "        self.oldReal_validity = torch.zeros(self.replay_buffer_size, device=device)\n",
    "        self.oldFake_validities = torch.zeros(self.replay_buffer_size, device=device)\n",
    "        self.z_replay = torch.zeros(self.replay_buffer_size, c.latent_dim + NUM_CLASSES, device=device)\n",
    "        self.age = torch.zeros(self.replay_buffer_size, device=device)\n",
    "        self.kickTopPercent = 0.25\n",
    "        self.openIndexes = torch.ones(self.replay_buffer_size, device=device)\n",
    "        self.real_validity_total = torch.zeros(1, device=device)\n",
    "        self.fake_validity_total = torch.zeros(1, device=device)\n",
    "        self.numSamples = 0\n",
    "\n",
    "    def fillReplayBuffer(self, real_validity, real_validities, fake_validity, fake_validities, z):\n",
    "        \"\"\"\n",
    "        samples (amouting to replay_buffer_size) will be evenly provided by all batches to fill the replay buffer in 1 epoch\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            self.real_validity_total += real_validities.sum()\n",
    "            self.fake_validity_total += fake_validities.sum()\n",
    "            self.numSamples += len(z)\n",
    "            openings = (self.openIndexes > 0).sum().item()\n",
    "            numSamples = len(z)  \n",
    "            if self.filledIndex < self.replay_buffer_size: \n",
    "                # start filling the buffer front to back, only fill self.samplesPerBatch to prevent, the early batches from dominanting the replay buffer\n",
    "                remaining = self.replay_buffer_size - self.filledIndex\n",
    "                numSelected = np.min([remaining, numSamples, self.samplesPerBatch])\n",
    "                selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "                indexes = torch.arange(self.filledIndex, self.filledIndex + len(selected))\n",
    "                self.filledIndex += len(selected)\n",
    "            elif openings:\n",
    "                # randomly select samples to fill the openIndexes in the replay buffer\n",
    "                indexes = torch.nonzero(self.openIndexes).squeeze()\n",
    "                numSelected = np.min([openings, numSamples, self.samplesPerBatch])\n",
    "                selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "                indexes = np.random.choice(indexes.numel(), numSelected, replace=False)\n",
    "            else:\n",
    "                return\n",
    "            self.oldFake_validity[indexes] = fake_validity.repeat(len(indexes))\n",
    "            self.oldReal_validity[indexes] = real_validity.repeat(len(indexes))\n",
    "            self.oldFake_validities[indexes] = fake_validities[selected].squeeze()\n",
    "            self.z_replay[indexes,:] = z[selected]\n",
    "            self.age[indexes] = 0\n",
    "            self.openIndexes[indexes] = 0\n",
    "\n",
    "    def plotReplayValidities(self):\n",
    "        i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(x=self.oldReal_validity[i_replays].cpu().numpy(), name=\"real\"))\n",
    "        fig.add_trace(go.Histogram(x=self.oldFake_validity[i_replays].cpu().numpy(), name=\"fake\"))\n",
    "        fig.update_layout(barmode='overlay', title=\"saved validity scores histogram\")\n",
    "        fig.show()\n",
    "\n",
    "    def update_learning_rate(self, epoch, d, g):\n",
    "        with torch.no_grad():\n",
    "            i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "            z_replay = self.z_replay[i_replays]\n",
    "            z_replay = z_replay.view(len(z_replay), c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "            fake_replay = g(z_replay)\n",
    "            replayFake_validities, _ = d(fake_replay)\n",
    "            replayFake_validities = replayFake_validities.squeeze()\n",
    "    \n",
    "            # if gaps are negatives then discriminator then fake images are getting higher validity scores than real ones\n",
    "            oldGap = (self.oldReal_validity[i_replays] - self.oldFake_validity[i_replays]).mean()\n",
    "            curGap = self.real_validity_total / self.numSamples - self.fake_validity_total / self.numSamples\n",
    "            # positive - smaller positive\n",
    "\n",
    "            replayScores = replayFake_validities - curGap.repeat(len(i_replays))\n",
    "            oldScores = self.oldFake_validities[i_replays] - oldGap.repeat(len(i_replays))\n",
    "\n",
    "            # logging\n",
    "            t_age[epoch] = self.age[i_replays].mean()\n",
    "            t_curGap[epoch] = curGap\n",
    "            t_oldGap[epoch] = oldGap\n",
    "            t_replayScore[epoch] = replayScores.mean()\n",
    "            t_oldScore[epoch] = oldScores.mean()\n",
    "            t_replayValidity[epoch] = replayFake_validities.mean()\n",
    "            t_oldValidity[epoch] = self.oldFake_validities[i_replays].mean()\n",
    "            # try:\n",
    "            #     wandb.log({\"curGap\": curGap, \"oldGap\": oldGap, \"replayScore\": replayScores.mean().item(), \"oldScore\": oldScores.mean().item(), 'avgAge': self.age[i_replays].mean().item()})\n",
    "            # except:\n",
    "            #     ...\n",
    "            if self.METRIC.value == LR_Metric.VALIDITY.value:\n",
    "                metric = replayFake_validities.squeeze()\n",
    "            elif self.METRIC.value == LR_Metric.AGE.value:\n",
    "                metric = self.age[i_replays].squeeze()\n",
    "                raise NotImplementedError(\"needs to be adjusted\")\n",
    "            else:\n",
    "                raise Exception(\"Invalid metric\")\n",
    "            # Kick out top 10% of the replay buffer based on replayScores scores\n",
    "            # lowest to highest, drop the highest\n",
    "            i_highestMetric = torch.argsort(metric)[-int(np.ceil(self.kickTopPercent * self.replay_buffer_size)):]\n",
    "            self.openIndexes[i_highestMetric] = 1\n",
    "\n",
    "            # kick out first half for testing\n",
    "            # self.openIndexes[:int(self.replay_buffer_size/2)] = torch.ones(int(self.replay_buffer_size/2)).to(device)\n",
    "\n",
    "            self.age += 1\n",
    "\n",
    "lr_scheduler_trial = LearningRateScheduler(initial_lr=0.001, replay_buffer_size=c.replay_buffer_size, total_batches=train_batches, batch_size=c.batch_size)\n",
    "d_lr_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(discriminator_optimizer, T_0=int(num_epochs/c.lr_restarts), T_mult=1, eta_min=min_lr)\n",
    "\n",
    "# d_lr_scheduler = lr_scheduler.\n",
    "classCriterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def createGridFakeImages(epoch=0, cubeSide=4, show=False, step=None, log=True):\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                        horizontal_spacing=0.01, \n",
    "                        shared_yaxes=True)\n",
    "    numImages = torch.tensor([cubeSide**2], device=device)\n",
    "    # Generate and plot fake images with labels\n",
    "    labels = torch.randint(0, 10, (numImages,), device=device)\n",
    "    labels_one_hot = torch.zeros(numImages, 10, device=device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(numImages, c.latent_dim, device=device)\n",
    "        g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "        g_input = g_input.view(numImages, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "        fake_images = generator(g_input)\n",
    "        # fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "        # g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "    fig = make_subplots(rows=cubeSide, cols=cubeSide, \n",
    "                        horizontal_spacing = 0.025,\n",
    "                        vertical_spacing = 0.04,\n",
    "                        subplot_titles=[str(label.item()) for label in labels])\n",
    "    fake_images = fake_images.squeeze().cpu().numpy()\n",
    "    for i in range(numImages):\n",
    "        r = int(i/cubeSide) + 1\n",
    "        c = int(i%cubeSide) + 1\n",
    "        imageFlipped = np.flip(fake_images[i], 0)\n",
    "        fig.add_trace(go.Heatmap(z=imageFlipped, \n",
    "                                colorscale='Greys',), row=r, col=c)\n",
    "    fig.update_layout(title_text=\"Generated Images epoch: \" + str(epoch), \n",
    "                    margin=dict(l=0, r=0, t=60, b=0),\n",
    "                    height=800, width=800, showlegend=False)\n",
    "    fig.update_traces(showscale=False)\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if log:\n",
    "        if step is None:\n",
    "            raise Exception(\"step must be provided when logging an image\")\n",
    "        # Convert the figure to a JPEG image and log using wandb\n",
    "        image_bytes = pio.to_image(fig, format='jpeg')\n",
    "        t_images.append((image_bytes, step))\n",
    "\n",
    "scaler = GradScaler()\n",
    "# GradScaler with PyTorch's autocast prevents gradient underflow in mixed precision training.\n",
    "# It achieves this by scaling up the loss before backward pass to keep float16 gradients from vanishing.\n",
    "# After gradients are computed, they are scaled back before the optimizer updates the model weights.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct, total = 0, 0\n",
    "    for i, (real_images, labels) in enumerate(train_loader):\n",
    "        # s_time = time.time()\n",
    "        # print(f\"Epoch {epoch}/{num_epochs} Batch {i}/{total_steps}\")\n",
    "        _batch_size = real_images.size(0)\n",
    "        real_images = real_images.unsqueeze(1)\n",
    "        labels_one_hot = torch.zeros(_batch_size, 10, device=device).scatter_(1, labels.view(_batch_size, 1), 1).to(device)\n",
    "\n",
    "        # train generator\n",
    "        # Setting gradients to zeroes by model.zero_grad() or optimizer.zero_grad() would execute memset for all parameters and update gradients with reading and writing operations. \n",
    "        # However, setting the gradients as None would not execute memset and would update gradients with only writing operations.\n",
    "        generator_optimizer.zero_grad(set_to_none=True)\n",
    "        z = torch.randn(_batch_size, c.latent_dim).to(device)\n",
    "        g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "        g_input = g_input.view(_batch_size, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "        fake_images = generator(g_input)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "        # g_loss should minimize the difference in predicting classes among the same classes\n",
    "        g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        # WGAN-GP\n",
    "        # g_loss = -torch.mean(fake_validities) + g_fakeClassLoss * lambda_class\n",
    "        d_logits_gen = fake_validities.view(-1)\n",
    "        # LSGAN\n",
    "        g_loss_base = criterion(d_logits_gen, torch.ones_like(d_logits_gen))\n",
    "        g_loss = g_loss_base + g_fakeClassLoss * c.lambda_class\n",
    "        scaler.scale(g_loss).backward()\n",
    "        scaler.step(generator_optimizer)\n",
    "        \n",
    "        # train discriminator\n",
    "        discriminator_optimizer.zero_grad(set_to_none=True)\n",
    "        real_validities, d_realClass = discriminator(real_images)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images.clone().detach())\n",
    "        loss_disc_real = criterion(real_validities, torch.ones_like(real_validities))\n",
    "        loss_disc_fake = criterion(fake_validities, -torch.ones_like(fake_validities)) # modified to -1 from normal LSGAN 0 target\n",
    "        # LSGAN\n",
    "        d_loss_base = (loss_disc_real + loss_disc_fake) / 2\n",
    "        \n",
    "        # gradient_penalty = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "        # d_loss = -torch.mean(real_validities) + torch.mean(fake_validities) + lambda_gp * gradient_penalty\n",
    "        d_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        d_fakeAccuracy = (d_fakeClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_realClassLoss = classCriterion(d_realClass, labels_one_hot)\n",
    "        d_realAccuracy = (d_realClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_loss = d_loss_base + (d_fakeClassLoss + d_realClassLoss) / 2\n",
    "        scaler.scale(d_loss).backward()\n",
    "        scaler.step(discriminator_optimizer)\n",
    "\n",
    "        correct += (real_validities > 0).sum().item() + (fake_validities < 0).sum().item()\n",
    "        total += len(real_validities) + len(fake_validities)\n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{train_batches}], d_loss: {d_loss_base.item():.4f}, g_loss: {g_loss.item():.4f}\")\n",
    "        g_input = g_input.view(_batch_size, c.latent_dim + NUM_CLASSES)\n",
    "        real_validity = real_validities.mean()\n",
    "        fake_validity = fake_validities.mean()\n",
    "        lr_scheduler_trial.fillReplayBuffer(real_validity, real_validities, fake_validity, fake_validities, g_input)\n",
    "        # print(\"lr_scheduler_trial: \", time.time() - s_time)\n",
    "        i_step = epoch * train_batches + i\n",
    "        t_real_validity[i_step] = real_validity\n",
    "        t_fake_validity[i_step] = fake_validity\n",
    "        t_d_fakeClassLoss[i_step] = d_fakeClassLoss\n",
    "        t_d_realClassLoss[i_step] = d_realClassLoss\n",
    "        t_d_fakeAccuracy[i_step] = d_fakeAccuracy\n",
    "        t_d_realAccuracy[i_step] = d_realAccuracy\n",
    "        t_d_loss_base[i_step] = d_loss_base\n",
    "        t_g_loss_base[i_step] = g_loss_base\n",
    "\n",
    "        scaler.update()\n",
    "            \n",
    "    d_lr_scheduler.step()\n",
    "    accuracy = correct / total\n",
    "\n",
    "    lr_scheduler_trial.update_learning_rate(epoch, discriminator, generator)\n",
    "\n",
    "    t_accuracy[epoch] = accuracy\n",
    "    t_d_lr[epoch] = discriminator_optimizer.param_groups[0]['lr']\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        createGridFakeImages(epoch=epoch,cubeSide=5, show=True, log=True, step=i_step)\n",
    "\n",
    "_t_age = t_age.cpu().detach().numpy()\n",
    "_t_curGap = t_curGap.cpu().detach().numpy()\n",
    "_t_oldGap = t_oldGap.cpu().detach().numpy()\n",
    "_t_oldScore = t_oldScore.cpu().detach().numpy()\n",
    "_t_replayScore = t_replayScore.cpu().detach().numpy()\n",
    "_t_replayValidity = t_replayValidity.cpu().detach().numpy()\n",
    "_t_oldValidity = t_oldValidity.cpu().detach().numpy()\n",
    "_t_accuracy = t_accuracy.cpu().detach().numpy()\n",
    "_t_d_lr = t_d_lr.cpu().detach().numpy()\n",
    "\n",
    "_t_real_validity = t_real_validity.cpu().detach().numpy()\n",
    "_t_fake_validity = t_fake_validity.cpu().detach().numpy()\n",
    "_t_d_fakeClassLoss = t_d_fakeClassLoss.cpu().detach().numpy()\n",
    "_t_d_realClassLoss = t_d_realClassLoss.cpu().detach().numpy()\n",
    "_t_d_fakeAccuracy = t_d_fakeAccuracy.cpu().detach().numpy()\n",
    "_t_d_realAccuracy = t_d_realAccuracy.cpu().detach().numpy()\n",
    "_t_d_loss_base = t_d_loss_base.cpu().detach().numpy()\n",
    "_t_g_loss_base = t_g_loss_base.cpu().detach().numpy()\n",
    "\n",
    "imageIndex = 0\n",
    "_t_images = t_images.copy()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(train_batches):\n",
    "        step = epoch * train_batches + i\n",
    "        if i != train_batches - 1:\n",
    "            metrics = {'real_validity': _t_real_validity[step],\n",
    "                        'fake_validity': _t_fake_validity[step], \n",
    "                        'd_fakeClassLoss': _t_d_fakeClassLoss[step], \n",
    "                        'd_realClassLoss': _t_d_realClassLoss[step], \n",
    "                        'd_fakeAccuracy': _t_d_fakeAccuracy[step], \n",
    "                        'd_realAccuracy': _t_d_realAccuracy[step], \n",
    "                        'd_loss_base': _t_d_loss_base[step], \n",
    "                        'g_loss_base': _t_g_loss_base[step]}\n",
    "            wandb.log(metrics, step=step)\n",
    "    epochMetrics = {'avgAge': _t_age[epoch], \n",
    "                       'curGap': _t_curGap[epoch], \n",
    "                       'oldGap': _t_oldGap[epoch], \n",
    "                       'oldScore': _t_oldScore[epoch], \n",
    "                       'replayScore': _t_replayScore[epoch], \n",
    "                       'replayValidity': _t_replayValidity[epoch], \n",
    "                       'oldValidity': _t_oldValidity[epoch], \n",
    "                       'accuracy': _t_accuracy[epoch], \n",
    "                       'd_lr': _t_d_lr[epoch], }\n",
    "    epochMetrics.update(metrics)\n",
    "    if len(_t_images) and _t_images[0][1] == step:\n",
    "        with TempFileContext() as tmp_filename:\n",
    "            image_bytes = _t_images[0][0]\n",
    "            with open(tmp_filename, 'wb') as tmp_file:\n",
    "                tmp_file.write(image_bytes)\n",
    "            epochMetrics['generator_output'] = wandb.Image(tmp_filename)\n",
    "            wandb.log(epochMetrics, step=step)\n",
    "        _t_images = _t_images[1:]\n",
    "    else:\n",
    "        wandb.log(epochMetrics, step=step)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_data = datasets.MNIST(\n",
    "    root='./dataset/minst/',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "train_data.train_data.to(torch.device(\"cuda:0\"))  # put data into GPU entirely\n",
    "train_data.train_labels.to(torch.device(\"cuda:0\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_fakeClassLoss:  2.302658796310425\n"
     ]
    }
   ],
   "source": [
    "numImages = torch.tensor([2000]).to(device)\n",
    "# Generate and plot fake images with labels\n",
    "labels = torch.randint(0, 10, (numImages,)).to(device)\n",
    "labels_one_hot = torch.zeros(numImages, 10).to(device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(numImages, c.latent_dim).to(device)\n",
    "    g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "    g_input = g_input.view(numImages, c.latent_dim + NUM_CLASSES, 1, 1)\n",
    "    fake_images = generator(g_input)\n",
    "    fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "    g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "\n",
    "fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "label_text = [str(label.item()) for label in labels]\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(numImages):\n",
    "    plt.subplot(int(numImages**0.5), int(numImages**0.5), i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(label_text[i], fontsize=10)\n",
    "    plt.imshow(fake_images[i].cpu().squeeze(), cmap='gray')\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.suptitle(\"Generated Images epoch: \" + str(epoch), fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# # save plotly\n",
    "\n",
    "# # Save the figure to a file\n",
    "# image_path = \"image.jpg\"\n",
    "# plt.savefig(image_path)\n",
    "# # Convert the saved image file to wandb.Image and log using wandb\n",
    "# with open(image_path, \"rb\") as img_file:\n",
    "#     img_data = img_file.read()\n",
    "#     image = Image.open(io.BytesIO(img_data))\n",
    "#     wandb.log({\"generator_output\": wandb.Image(image)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
