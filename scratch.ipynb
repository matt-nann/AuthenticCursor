{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an optimizer\n",
    "initial_lr = 0.001\n",
    "min_lr = 0.000001\n",
    "optimizer = torch.optim.SGD([torch.randn(1, requires_grad=True)], lr= initial_lr)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 100\n",
    "cycles = 4\n",
    "# Learning rate schedulers\n",
    "cosineAnnealingWarmRestarts = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "schedulers = {\n",
    "    # \"LambdaLR\": lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "    # \"MultiplicativeLR\": lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.95),\n",
    "    # \"StepLR\": lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1),\n",
    "    # \"MultiStepLR\": lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.1),\n",
    "    # \"ConstantLR\": lr_scheduler.ConstantLR(optimizer),\n",
    "    # \"LinearLR\" : lr_scheduler.LinearLR(optimizer),\n",
    "    # \"ExponentialLR\": lr_scheduler.ExponentialLR(optimizer, gamma=0.1),\n",
    "    # \"PolynomialLR\": lr_scheduler.PolynomialLR(optimizer,total_iters=4, power=1.0),\n",
    "    # \"CosineAnnealingLR\": lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0),\n",
    "    \"ChainedScheduler\" : lr_scheduler.ChainedScheduler([lr_scheduler.ConstantLR(optimizer, total_iters=10), cosineAnnealingWarmRestarts]),\n",
    "    # \"SequentialLR\": lr_scheduler.SequentialLR(optimizer, schedulers=[lr_scheduler.ConstantLR(optimizer, factor=0.1, total_iters=2), lr_scheduler.ExponentialLR(optimizer, gamma=0.9)], milestones=[2]),\n",
    "    # \"ReduceLROnPlateau\": lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10),\n",
    "    # \"CyclicLR\": lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=1, step_size_up=5, mode='triangular2'),\n",
    "    # \"OneCycleLR\": lr_scheduler.OneCycleLR(optimizer, max_lr=1, total_steps=num_epochs),\n",
    "    # \"CosineAnnealingWarmRestarts\": lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=int(num_epochs/cycles), T_mult=1, eta_min=min_lr)\n",
    "}\n",
    "\n",
    "# Create a plot for each scheduler\n",
    "for name, scheduler in schedulers.items():\n",
    "    lrs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.step()\n",
    "        lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "        if name != \"ReduceLROnPlateau\":\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step(epoch)  # Assume loss is decreasing with epoch for this example\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(lrs)\n",
    "    plt.title(name)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.system(\"pip install wandb\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import plotly.io as pio\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import wandb\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "class TempFileContext:\n",
    "    def __enter__(self):\n",
    "        self.tmp_file = tempfile.NamedTemporaryFile(suffix=\".jpeg\", delete=False)\n",
    "        self.tmp_filename = self.tmp_file.name\n",
    "        return self.tmp_filename\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.tmp_file.close()\n",
    "        os.remove(self.tmp_filename)\n",
    "\n",
    "# As per the DCGAN paper: All the weights are initialized from a zero centered normal distribution with standard deviation 0.02\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g, num_classes):\n",
    "        \"\"\"\n",
    "        channels_noise: The size of the input noise vector. This noise vector is a random input from which the generator begins the generation of a new sample.\n",
    "        channels_img: The number of output channels of the generator. This will typically be 1 for grayscale images or 3 for color (RGB) images.\n",
    "        features_g: This is the base size of the feature maps in the generator. The number of neurons or nodes in each layer of the generator is a multiple of this base size.\n",
    "        num_classes: The number of distinct classes or labels that the generator should generate images for. This is used to form the one-hot vector of class labels, which is concatenated to the noise vector to provide the generator with information about the class of image to generate.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.channels_noise = channels_noise\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "            self.gen_block(channels_noise + num_classes, 256, kernel_size=7, stride=1, padding=0), # Append class labels to input noise.\n",
    "            self.gen_block(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ConvTranspose2d(128, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def gen_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.gen(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, num_classes, num_kernels, kernel_dim):\n",
    "        \"\"\"\n",
    "        channels_img: The number of input channels to the discriminator, corresponding to the number of channels in the images to be classified.\n",
    "        features_d: This is the base size of the feature maps in the discriminator. The number of neurons or nodes in each layer of the discriminator is a multiple of this base size.\n",
    "        num_classes: The number of distinct classes that the discriminator should be able to distinguish between. This is used to form the softmax output layer of the discriminator, which outputs a class probability distribution.\n",
    "        num_kernels and kernel_dim: These are parameters for the minibatch discrimination layer. The minibatch discrimination layer is designed to make the discriminator sensitive to the variety of samples within a minibatch, to encourage the generator to generate a variety of different samples. num_kernels is the number of unique patterns the layer can learn to identify, and kernel_dim is the size of these learned patterns.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            self._block(64, 128, 4, 2, 1),\n",
    "        )\n",
    "        self.mbd = MinibatchDiscrimination(128*7*7, num_kernels, kernel_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128*7*7 + num_kernels, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1 + num_classes),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mbd(x)\n",
    "        out = self.fc(x)\n",
    "        return out[:, 0], nn.functional.softmax(out[:, 1:], dim=1)\n",
    "\n",
    "\n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self, input_features, num_kernels, kernel_dim):\n",
    "        super(MinibatchDiscrimination, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.num_kernels = num_kernels\n",
    "        self.kernel_dim = kernel_dim\n",
    "        self.T = nn.Parameter(torch.randn(input_features, num_kernels * kernel_dim))\n",
    "    def forward(self, x):\n",
    "        M = torch.matmul(x, self.T).view(-1, self.num_kernels, self.kernel_dim)\n",
    "        diffs = M.unsqueeze(0) - M.transpose(0, 1).unsqueeze(2)\n",
    "        abs_diffs = torch.sum(torch.abs(diffs), dim=2)\n",
    "        minibatch_features = torch.sum(torch.exp(-abs_diffs), dim=2).T\n",
    "        return torch.cat((x, minibatch_features), dim=1)\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples, phi=1):\n",
    "    assert real_samples.shape == fake_samples.shape\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    # alpha = torch.rand((real_samples.size(0), 1)).to(device).requires_grad_(False)\n",
    "    alpha = torch.rand((real_samples.size(0), 1, 1, 1)).to(device).requires_grad_(False)\n",
    "    real_samples.requires_grad_(True)\n",
    "    fake_samples.requires_grad_(True)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolated = alpha * real_samples + (1 - alpha) * fake_samples\n",
    "    # calculate probability of interpolated examples\n",
    "    # with torch.backends.cudnn.flags(enabled=False):\n",
    "    prob_interpolated, _ = D(interpolated)\n",
    "    ones = torch.ones(prob_interpolated.size()).to(device).requires_grad_(True)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=prob_interpolated,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=ones,\n",
    "        create_graph=True)[0]\n",
    "    gradients = gradients.reshape(gradients.size(0), -1)\n",
    "    gradient_penalty = (\n",
    "        torch.mean((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2)\n",
    "    )   \n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class LR_Metric(Enum):\n",
    "    VALIDITY = 1\n",
    "    AGE = 2\n",
    "\n",
    "# why would age be beneficial\n",
    "\n",
    "\n",
    "class LearningRateScheduler:\n",
    "    def __init__(self, initial_lr, replay_buffer_size, total_batches, batch_size, METRIC=LR_Metric.VALIDITY):\n",
    "        self.initial_lr = initial_lr\n",
    "        self.replay_buffer_size = replay_buffer_size\n",
    "        self.total_batches = total_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.METRIC = METRIC\n",
    "        self.samplesPerBatch = int(np.ceil(replay_buffer_size / total_batches))\n",
    "        self.filledIndex = 0\n",
    "        self.oldFake_validity = torch.zeros(self.replay_buffer_size).to(device)\n",
    "        self.oldReal_validity = torch.zeros(self.replay_buffer_size).to(device)\n",
    "        self.oldFake_validities = torch.zeros(self.replay_buffer_size).to(device)\n",
    "        self.z_replay = torch.zeros(self.replay_buffer_size, latent_dim + NUM_CLASSES).to(device)\n",
    "        self.age = torch.zeros(self.replay_buffer_size).to(device)\n",
    "        self.kickTopPercent = 0.25\n",
    "        self.openIndexes = torch.ones(self.replay_buffer_size).to(device)\n",
    "        self.real_validity_total = torch.Tensor([0]).to(device)\n",
    "        self.fake_validity_total = torch.Tensor([0]).to(device)\n",
    "        self.numSamples = 0\n",
    "\n",
    "    def fillReplayBuffer(self, real_validity, real_validities, fake_validity, fake_validities, z):\n",
    "        \"\"\"\n",
    "        samples (amouting to replay_buffer_size) will be evenly provided by all batches to fill the replay buffer in 1 epoch\n",
    "        \"\"\"\n",
    "        self.real_validity_total += real_validities.sum()\n",
    "        self.fake_validity_total += fake_validities.sum()\n",
    "        self.numSamples += len(z)\n",
    "        openings = (self.openIndexes > 0).sum().item()\n",
    "        numSamples = len(z)  \n",
    "        if self.filledIndex < self.replay_buffer_size: \n",
    "            # start filling the buffer front to back, only fill self.samplesPerBatch to prevent, the early batches from dominanting the replay buffer\n",
    "            remaining = self.replay_buffer_size - self.filledIndex\n",
    "            numSelected = np.min([remaining, numSamples, self.samplesPerBatch])\n",
    "            selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "            indexes = torch.arange(self.filledIndex, self.filledIndex + len(selected))\n",
    "            self.filledIndex += len(selected)\n",
    "        elif openings:\n",
    "            # randomly select samples to fill the openIndexes in the replay buffer\n",
    "            indexes = torch.nonzero(self.openIndexes).squeeze()\n",
    "            numSelected = np.min([openings, numSamples, self.samplesPerBatch])\n",
    "            selected = np.random.choice(numSamples, numSelected, replace=False)\n",
    "            indexes = np.random.choice(indexes.numel(), numSelected, replace=False)\n",
    "        else:\n",
    "            return\n",
    "        self.oldFake_validity[indexes] = fake_validity.repeat(len(indexes))\n",
    "        self.oldReal_validity[indexes] = real_validity.repeat(len(indexes))\n",
    "        self.oldFake_validities[indexes] = fake_validities[selected].squeeze()\n",
    "        self.z_replay[indexes,:] = z[selected]\n",
    "        self.age[indexes] = 0\n",
    "        self.openIndexes[indexes] = 0\n",
    "\n",
    "    def plotReplayValidities(self):\n",
    "        i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(x=self.oldReal_validity[i_replays].cpu().numpy(), name=\"real\"))\n",
    "        fig.add_trace(go.Histogram(x=self.oldFake_validity[i_replays].cpu().numpy(), name=\"fake\"))\n",
    "        fig.update_layout(barmode='overlay', title=\"saved validity scores histogram\")\n",
    "        fig.show()\n",
    "\n",
    "    def update_learning_rate(self, d, g):\n",
    "        with torch.no_grad():\n",
    "            i_replays = (self.openIndexes == 0).nonzero().squeeze()\n",
    "            z_replay = self.z_replay[i_replays]\n",
    "            z_replay = z_replay.view(len(z_replay), latent_dim + NUM_CLASSES, 1, 1)\n",
    "            fake_replay = g(z_replay)\n",
    "            replayFake_validities, _ = d(fake_replay)\n",
    "            replayFake_validities = replayFake_validities.squeeze()\n",
    "    \n",
    "            # if gaps are negatives then discriminator then fake images are getting higher validity scores than real ones\n",
    "            oldGap = (self.oldReal_validity[i_replays] - self.oldFake_validity[i_replays]).mean()\n",
    "            curGap = self.real_validity_total / self.numSamples - self.fake_validity_total / self.numSamples\n",
    "            # positive - smaller positive\n",
    "\n",
    "            replayScores = replayFake_validities - curGap.repeat(len(i_replays))\n",
    "            oldScores = self.oldFake_validities[i_replays] - oldGap.repeat(len(i_replays))\n",
    "            # print(\"replayScore: \", replayScores, \"oldScore: \", oldScores)\n",
    "            try:\n",
    "                wandb.log({\"curGap\": curGap, \"oldGap\": oldGap, \"replayScore\": replayScores.mean().item(), \"oldScore\": oldScores.mean().item()})\n",
    "            except:\n",
    "                ...\n",
    "            if self.METRIC.value == LR_Metric.VALIDITY.value:\n",
    "                metric = replayFake_validities.squeeze()\n",
    "            elif self.METRIC.value == LR_Metric.AGE.value:\n",
    "                metric = self.age[i_replays].squeeze()\n",
    "                raise NotImplementedError(\"needs to be adjusted\")\n",
    "            else:\n",
    "                raise Exception(\"Invalid metric\")\n",
    "            # Kick out top 10% of the replay buffer based on replayScores scores\n",
    "            # lowest to highest, drop the highest\n",
    "            i_highestMetric = torch.argsort(metric)[-int(np.ceil(self.kickTopPercent * self.replay_buffer_size)):]\n",
    "            self.openIndexes[i_highestMetric] = 1\n",
    "\n",
    "            # kick out first half for testing\n",
    "            # self.openIndexes[:int(self.replay_buffer_size/2)] = torch.ones(int(self.replay_buffer_size/2)).to(device)\n",
    "\n",
    "            # kick out according \n",
    "\n",
    "            self.age += 1\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "batch_size = 256 * 2\n",
    "# batch_size = 4\n",
    "num_epochs = 100\n",
    "num_kernels = 10\n",
    "kernel_dim = 3\n",
    "lambda_gp = 10  # Gradient penalty lambda hyperparameter\n",
    "learning_rate = 0.0002\n",
    "lr_restarts = 5\n",
    "min_lr = 1e-9\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = MNIST('data/MNIST', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "generator = Generator(latent_dim, 1, 32, NUM_CLASSES).to(device)\n",
    "initialize_weights(generator)\n",
    "discriminator = Discriminator(1, NUM_CLASSES, num_kernels, kernel_dim).to(device)\n",
    "initialize_weights(discriminator)\n",
    "\n",
    "# Loss weights\n",
    "real_label = -1.\n",
    "fake_label = 1.\n",
    "# Optimizers\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\\\n",
    "\n",
    "lambda_class = 1\n",
    "replay_buffer_size = 10000\n",
    "total_batches = len(dataloader)\n",
    "lr_scheduler_trial = LearningRateScheduler(initial_lr=0.001, replay_buffer_size=replay_buffer_size, total_batches=total_batches, batch_size=batch_size)\n",
    "d_lr_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(discriminator_optimizer, T_0=int(num_epochs/lr_restarts), T_mult=1, eta_min=min_lr)\n",
    "\n",
    "# d_lr_scheduler = lr_scheduler.\n",
    "classCriterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "import time\n",
    "# wandb.init(project=\"gan\")\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    for i, (real_images, labels) in enumerate(dataloader):\n",
    "        # s_time = time.time()\n",
    "        # print(f\"Epoch {epoch}/{num_epochs} Batch {i}/{total_steps}\")\n",
    "        _batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        # one hot encode labels\n",
    "        labels_one_hot = torch.zeros(_batch_size, 10).scatter_(1, labels.view(_batch_size, 1), 1).to(device)\n",
    "\n",
    "        # train generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        z = torch.randn(_batch_size, latent_dim).to(device)\n",
    "        g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "        g_input = g_input.view(_batch_size, latent_dim + NUM_CLASSES, 1, 1)\n",
    "        fake_images = generator(g_input)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images)\n",
    "        # g_loss should minimize the difference in predicting classes among the same classes\n",
    "        g_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        # WGAN-GP\n",
    "        # g_loss = -torch.mean(fake_validities) + g_fakeClassLoss * lambda_class\n",
    "        d_logits_gen = fake_validities.view(-1)\n",
    "        # LSGAN\n",
    "        g_loss = criterion(d_logits_gen, torch.ones_like(d_logits_gen))\n",
    "        g_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        # train discriminator\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        real_validities, d_realClass = discriminator(real_images)\n",
    "        fake_validities, d_fakeClass = discriminator(fake_images.clone().detach())\n",
    "        loss_disc_real = criterion(real_validities, torch.ones_like(real_validities))\n",
    "        loss_disc_fake = criterion(fake_validities, -torch.ones_like(fake_validities)) # modified to -1 from normal LSGAN 0 target\n",
    "        # LSGAN\n",
    "        d_loss = (loss_disc_real + loss_disc_fake) / 2\n",
    "        \n",
    "        # gradient_penalty = compute_gradient_penalty(discriminator, real_images.data, fake_images.data)\n",
    "        # d_loss = -torch.mean(real_validities) + torch.mean(fake_validities) + lambda_gp * gradient_penalty\n",
    "        d_fakeClassLoss = classCriterion(d_fakeClass, labels_one_hot)\n",
    "        d_fakeAccuracy = (d_fakeClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_realClassLoss = classCriterion(d_realClass, labels_one_hot)\n",
    "        d_realAccuracy = (d_realClass.argmax(dim=1) == labels_one_hot.argmax(dim=1)).float().mean()\n",
    "        d_loss = d_loss + (d_fakeClassLoss + d_realClassLoss) / 2\n",
    "        d_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        correct += (real_validities > 0).sum().item() + (fake_validities < 0).sum().item()\n",
    "\n",
    "        wandb.log({\"real_validity\": real_validities.mean().item(), \"fake_validity\": fake_validities.mean().item(), \\\n",
    "                \"d_fakeClassLoss\": d_fakeClassLoss.item(), \"d_realClassLoss\": d_realClassLoss.item(), \\\n",
    "                \"d_fakeAccuracy\": d_fakeAccuracy.item(), \"d_realAccuracy\": d_realAccuracy.item(), \\\n",
    "                    \"d_loss\": d_loss.item(), \"g_loss\": g_loss.item()})\n",
    "\n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_batches}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")\n",
    "        s_time = time.time()\n",
    "        g_input = g_input.view(_batch_size, latent_dim + NUM_CLASSES)\n",
    "        lr_scheduler_trial.fillReplayBuffer(real_validities.mean(), real_validities, fake_validities.mean(), fake_validities, g_input)\n",
    "        # print(\"lr_scheduler_trial: \", time.time() - s_time)\n",
    "    \n",
    "    d_lr_scheduler.step()\n",
    "    try:\n",
    "        accuracy = correct / total_batches / _batch_size / 2\n",
    "        wandb.log({\"lr\": discriminator_optimizer.param_groups[0]['lr'], \"accuracy\": accuracy})\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], lr: {discriminator_optimizer.param_groups[0]['lr']}\")\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "    lr_scheduler_trial.update_learning_rate(discriminator, generator)\n",
    "\n",
    "    # if epoch % 5 == 0:\n",
    "    numImages = torch.tensor([16]).to(device)\n",
    "    # Generate and plot fake images with labels\n",
    "    labels = torch.randint(0, 10, (numImages,)).to(device)\n",
    "    labels_one_hot = torch.zeros(numImages, 10).to(device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "    with torch.no_grad():\n",
    "          z = torch.randn(numImages, latent_dim).to(device)\n",
    "          g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "          g_input = g_input.view(numImages, latent_dim + NUM_CLASSES, 1, 1)\n",
    "          fake_images = generator(g_input)\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    label_text = [str(label.item()) for label in labels]\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i in range(numImages):\n",
    "        plt.subplot(int(numImages**0.5), int(numImages**0.5), i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(label_text[i], fontsize=10)\n",
    "        plt.imshow(fake_images[i].cpu().squeeze(), cmap='gray')\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "    plt.suptitle(\"Generated Images epoch: \" + str(epoch), fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # # Save the figure to a file\n",
    "    # image_path = \"image.jpg\"\n",
    "    # plt.savefig(image_path)\n",
    "    # # Convert the saved image file to wandb.Image and log using wandb\n",
    "    # with open(image_path, \"rb\") as img_file:\n",
    "    #     img_data = img_file.read()\n",
    "    #     image = Image.open(io.BytesIO(img_data))\n",
    "    #     wandb.log({\"generator_output\": wandb.Image(image)})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_real_validity = torch.zeros(total_batches).to(device).requires_grad_(False)\n",
    "track_fake_validity = torch.zeros(total_batches).to(device).requires_grad_(False)\n",
    "track_d_fakeClassLoss = torch.zeros(total_batches).to(device).requires_grad_(False)\n",
    "track_d_realClassLoss = torch.zeros(total_batches).to(device).requires_grad_(False)\n",
    "track_d_loss = torch.zeros(total_batches).to(device).requires_grad_(False)\n",
    "track_g_loss = torch.zeros(total_batches).to(device).requires_grad_(False)  \n",
    "   # track_real_validity = track_real_validity.cpu().numpy()\n",
    "    # track_fake_validity = track_fake_validity.cpu().numpy()\n",
    "    # track_d_fakeClassLoss = track_d_fakeClassLoss.cpu().numpy()\n",
    "    # track_d_realClassLoss = track_d_realClassLoss.cpu().numpy()\n",
    "    # track_d_loss = track_d_loss.cpu().numpy()\n",
    "    # track_g_loss = track_g_loss.cpu().numpy()\n",
    "    # for i in range(total_batches):\n",
    "    #     wandb.log({\"real_validity\": track_real_validity[i], \"fake_validity\": track_fake_validity[i], \\\n",
    "    #                 \"d_fakeClassLoss\": track_d_fakeClassLoss[i], \"d_realClassLoss\": track_d_realClassLoss[i], \\\n",
    "    #                 \"d_loss\": track_d_loss[i], \"g_loss\": track_g_loss[i]}, step=i + epoch * total_batches)\n",
    "        \n",
    "# return fake_validities_replay.mean()\n",
    "                # for i, (fake_validity, z, real_validity, fake_validities, time_diff) in enumerate(self.replay_buffer):\n",
    "                #     # if fake_validity < fake_validities[i]:\n",
    "                #     #     self.replay_buffer[i] = [fake_validities[i], z, real_validity, fake_validities, 0]\n",
    "                #     g(z)\n",
    "                #     current_validity = \n",
    "\n",
    "            #     # Update the learning rate based on the discriminator's performance and time information\n",
    "            #     validity_differences = []\n",
    "            #     time_differences = []\n",
    "            #     for i, (ake_validity, real_validity, validities, time_diff) in enumerate(self.replay_buffer):\n",
    "                    \n",
    "\n",
    "            #     avg_past_loss = sum(past_losses) / len(past_losses)\n",
    "            #     current_loss = fake_validities.item()\n",
    "            #     current_time_diff = 0\n",
    "\n",
    "            #     if current_loss < avg_past_loss:\n",
    "            #         # Store the current image with its loss and time difference\n",
    "            #         self.replay_buffer.append((generator.state_dict(), discriminator.state_dict(), losses, current_time_diff))\n",
    "            #         self.replay_buffer = sorted(self.replay_buffer, key=lambda x: x[2].item())  # Sort by loss (ascending)\n",
    "            #         # Remove the worst image from the replay buffer\n",
    "            #         self.replay_buffer.pop()\n",
    "            #         # Compute the discriminator loss improvement over time\n",
    "            #         discriminator_loss_improvement = sum(past_losses) - avg_past_loss * len(past_losses)\n",
    "            #         if discriminator_loss_improvement > 0:\n",
    "            #             # Compute the learning rate adjustment based on the discriminator loss improvement\n",
    "            #             lr_adjustment = generator.optimizer.param_groups[0]['lr'] * (1 + discriminator_loss_improvement)\n",
    "            #             # Increase the learning rate for the generator\n",
    "            #             generator.optimizer.param_groups[0]['lr'] = lr_adjustment\n",
    "            #             print(\"Increased learning rate to:\", lr_adjustment)\n",
    "            #     # Update the time differences for the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numImages = torch.tensor([16]).to(device)\n",
    "# Generate and plot fake images with labels\n",
    "labels = torch.randint(0, 10, (numImages,)).to(device)\n",
    "labels_one_hot = torch.zeros(numImages, 10).to(device).scatter_(1, labels.view(numImages, 1), 1)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(numImages, latent_dim).to(device)\n",
    "    g_input = torch.cat((z, labels_one_hot), dim=1)\n",
    "    fake_images = generator(g_input)\n",
    "fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "label_text = [str(label.item()) for label in labels]\n",
    "plt.figure(figsize=(5, 5))\n",
    "for i in range(numImages):\n",
    "    plt.subplot(int(numImages**0.5), int(numImages**0.5), i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(label_text[i], fontsize=10)\n",
    "    plt.imshow(fake_images[i].cpu().squeeze(), cmap='gray')\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "plt.suptitle(\"Generated Images epoch: \" + str(epoch), fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
